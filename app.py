import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import sys
from sklearn.metrics import mean_absolute_error
import plotly.graph_objects as go

sys.path.append(os.path.dirname(__file__))

from utils import (
    load_data, get_latest_row, get_latest_n_rows,
    create_advanced_features, get_feature_columns, create_lstm_features,
    train_layer1_model, train_svr_model, train_layer2_model, load_model, save_model,
    predict_next_day_layer1, predict_layer2, create_prediction_with_confidence,
    evaluate_model, get_feature_importance, prepare_data_for_training,
    predict_multi_step_layer1, train_multi_horizon_models, 
    train_lstm_model, prepare_lstm_data, predict_lstm,
    plot_price_history, plot_candlestick, plot_volume,
    plot_technical_indicators, plot_prediction_result, plot_feature_importance,
    get_next_trading_date, format_number, calculate_change_percent,
    append_prediction_to_csv, validate_data
)

# Page config
st.set_page_config(
    page_title="H·ªá th·ªëng D·ª± b√°o Gi√° XRP ƒêa t·∫ßng",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        background: linear-gradient(90deg, #00D9FF 0%, #FF6B6B 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        padding: 1rem 0;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        color: white;
    }
    .prediction-box {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        padding: 2rem;
        border-radius: 15px;
        text-align: center;
        box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);
        color: white;
    }
    .stButton>button {
        background: linear-gradient(90deg, #00D9FF 0%, #4ECDC4 100%);
        color: white;
        font-weight: bold;
        border: none;
        padding: 0.5rem 2rem;
        border-radius: 25px;
        transition: all 0.3s;
    }
    .stButton>button:hover {
        transform: scale(1.05);
        box-shadow: 0 4px 12px rgba(0, 217, 255, 0.4);
    }
</style>
""", unsafe_allow_html=True)

DISPLAY_DATA_PATH = './data/XRPUSDT_train.csv'
SOURCE_DATA_PATH = './data/XRPUSDT20182024new.csv'

# Layer 1 paths
L1_MODEL_PATH = './models/layer1_rf_model.pkl'
L1_SCALER_PATH = './models/layer1_scaler.pkl'
L1_MULTI_MODELS_PATH = './models/layer1_multi_models.pkl'
L1_MULTI_SCALERS_PATH = './models/layer1_multi_scalers.pkl'
L1_SVR_MODEL_PATH = './models/layer1_svr_model.pkl'
L1_SVR_SCALER_PATH = './models/layer1_svr_scaler.pkl'
# Layer 2 paths
L2_RIDGE_MODEL_PATH = './models/layer2_ridge_model.pkl'
L2_RIDGE_SCALER_PATH = './models/layer2_ridge_scaler.pkl'
L2_SVR_MODEL_PATH = './models/layer2_svr_model.pkl'
L2_SVR_SCALER_PATH = './models/layer2_svr_scaler.pkl'
# Layer 3 paths
L3_MODEL_PATH = './models/layer3_lstm_model.keras'
L3_SCALER_PATH = './models/layer3_scaler.pkl'
L3_TARGET_SCALER_PATH = './models/layer3_target_scaler.pkl'

# Session state initialization
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False
if 'model' not in st.session_state:
    st.session_state.model = None
if 'scaler' not in st.session_state:
    st.session_state.scaler = None
if 'l1_multi_models' not in st.session_state:
    st.session_state.l1_multi_models = None
if 'l1_multi_scalers' not in st.session_state:
    st.session_state.l1_multi_scalers = None
if 'svr_model' not in st.session_state:
    st.session_state.svr_model = None
if 'svr_scaler' not in st.session_state:
    st.session_state.svr_scaler = None
if 'svr_model_trained' not in st.session_state:
    st.session_state.svr_model_trained = False
if 'df_features' not in st.session_state:
    st.session_state.df_features = None
if 'show_manual_input' not in st.session_state:
    st.session_state.show_manual_input = False
if 'metrics' not in st.session_state:
    st.session_state.metrics = None
if 'svr_metrics' not in st.session_state:
    st.session_state.svr_metrics = None

# Layer 2 Session States
if 'l2_ridge_model_trained' not in st.session_state:
    st.session_state.l2_ridge_model_trained = False
if 'l2_ridge_model' not in st.session_state:
    st.session_state.l2_ridge_model = None
if 'l2_ridge_scaler' not in st.session_state:
    st.session_state.l2_ridge_scaler = None

if 'l2_svr_model_trained' not in st.session_state:
    st.session_state.l2_svr_model_trained = False
if 'l2_svr_model' not in st.session_state:
    st.session_state.l2_svr_model = None
if 'l2_svr_scaler' not in st.session_state:
    st.session_state.l2_svr_scaler = None

# Layer 3 Session States
if 'l3_model_trained' not in st.session_state:
    st.session_state.l3_model_trained = False
if 'l3_model' not in st.session_state:
    st.session_state.l3_model = None
if 'l3_scaler' not in st.session_state:
    st.session_state.l3_scaler = None
if 'l3_target_scaler' not in st.session_state:
    st.session_state.l3_target_scaler = None

def main():

    # Header
    st.markdown('<h1 class="main-header">D·ª∞ B√ÅO GI√Å XRP - 3 LAYER HYBRID SYSTEM</h1>', unsafe_allow_html=True)
    st.markdown("---")
    
    # Sidebar
    with st.sidebar:
        st.title("Ph√¢n t√≠ch ƒêa t·∫ßng")
        st.info("""
        **H·ªá th·ªëng d·ª± b√°o 3 l·ªõp:**
        1. **Layer 1 (ML)**: ƒê·ªãnh h∆∞·ªõng xu h∆∞·ªõng trung h·∫°n (RandomForest).
        2. **Layer 2 (Stat)**: Tinh ch·ªânh d·ª± b√°o trong ng√†y (Ridge).
        3. **Layer 3 (DL)**: D·ª± b√°o chu·ªói th·ªùi gian 7 ng√†y (LSTM).
        """)
        
        if st.button("T·∫£i & X·ª≠ l√Ω d·ªØ li·ªáu th√¥"):
            load_and_process_data()
        
        if st.session_state.df_features is not None:
            st.success("D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng!")
            st.write(f"T·ªïng s·ªë d√≤ng: {len(st.session_state.df_features)}")
    
    # Tabs for different Layers
    tab1, tab2, tab3 = st.tabs(["üìä Layer 1: Xu h∆∞·ªõng", "üéØ Layer 2: Trong ng√†y", "üß† Layer 3: Deep Learning"])
    
    with tab1:
        display_layer1_content()
    
    with tab2:
        display_layer2_content()
        
    with tab3:
        display_layer3_content()


def display_layer1_content():
    
    # Control buttons at top
    # Control buttons at top
    st.subheader("ƒêi·ªÅu khi·ªÉn m√¥ h√¨nh Layer 1")
    
    col_up, col_cmd = st.columns([2, 1])
    with col_up:
        uploaded_file = st.file_uploader("üìÇ T·∫£i l√™n t·ªáp CSV d·ªØ li·ªáu", type=['csv'], label_visibility="collapsed")
        if uploaded_file is not None:
            if st.button("üöÄ S·ª≠ d·ª•ng t·ªáp v·ª´a t·∫£i l√™n", use_container_width=True):
                load_and_process_data(uploaded_file)
    
    with col_cmd:
        if st.button("üîÑ L·∫•y d·ªØ li·ªáu m·∫∑c ƒë·ªãnh", use_container_width=True, help="T·∫£i d·ªØ li·ªáu t·ª´ file train g·ªëc"):
            load_and_process_data()

    st.markdown("<br>", unsafe_allow_html=True)

    with st.expander("üõ†Ô∏è Hu·∫•n luy·ªán M√¥ h√¨nh Layer 1", expanded=True):
        train_col1, train_col2 = st.columns(2)
        with train_col1:
            if st.button("üå≤ Train RandomForest", use_container_width=True, disabled=st.session_state.df_features is None):
                train_model(model_type="RF")
        with train_col2:
            if st.button("üìà Train SVR", use_container_width=True, disabled=st.session_state.df_features is None):
                train_model(model_type="SVR")

    st.markdown("<br>", unsafe_allow_html=True)
    
    col_p1, col_p2, col_p3, col_p4 = st.columns(4)
    with col_p1:
        if st.button("üìÇ Load saved model", use_container_width=True):
            load_saved_model()
    with col_p2:
        if st.button("üîÆ D·ª± ƒëo√°n 1 ng√†y", use_container_width=True, 
                     disabled=not (st.session_state.model_trained or st.session_state.svr_model_trained)):
            make_prediction()
    with col_p3:
        if st.button("üìÖ D·ª± ƒëo√°n 7 ng√†y", use_container_width=True, 
                     disabled=not (st.session_state.model_trained or st.session_state.svr_model_trained)):
            make_7day_prediction()
    with col_p4:
        if st.button("üóëÔ∏è X√≥a model c≈©", use_container_width=True):
            delete_old_models()
    
    st.markdown("---")
    
    # Display dashboard if data is loaded
    if st.session_state.df_features is not None:
        display_dashboard()
    else:
        st.info("Vui l√≤ng nh·∫•n **T·∫£i d·ªØ li·ªáu** ƒë·ªÉ b·∫Øt ƒë·∫ßu")


#### load d·ªØ li·ªáu
def load_and_process_data(file_buffer=None, target_path=None):
    with st.spinner("ƒêang t·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu..."):
        try:
            # Load data
            if file_buffer is not None:
                df = pd.read_csv(file_buffer)
                df['Date'] = pd.to_datetime(df['Date'])
                df.drop(columns=['Change %'], errors='ignore', inplace=True)
                df = df.sort_values('Date').reset_index(drop=True)
            else:
                path = target_path if target_path else SOURCE_DATA_PATH
                df = load_data(path)
            
            # Validate
            is_valid, msg = validate_data(df)
            if not is_valid:
                st.error(f"D·ªØ li·ªáu kh√¥ng h·ª£p l·ªá: {msg}")
                return
            
            # Create features
            df_features = create_advanced_features(df)
            
            # # Sync RF & SVR predictions if they exist in the loaded file
            # if 'RF_Pred_Tomorrow' in df_features.columns:
            #     df_features['RF_Pred_Today'] = df_features['RF_Pred_Tomorrow'].shift(1)
            # if 'SVR_Pred_Tomorrow' in df_features.columns:
            #     df_features['SVR_Pred_Today'] = df_features['SVR_Pred_Tomorrow'].shift(1)
                
            # Store in session state
            st.session_state.df_features = df_features
            st.success(f"ƒê√£ t·∫£i {len(df)} d√≤ng d·ªØ li·ªáu t·ª´ {target_path if target_path else 'file ngu·ªìn'} th√†nh c√¥ng!")
            
        except Exception as e:
            st.error(f"L·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu: {e}")


#### train model
def train_model(model_type="RF"):
    if st.session_state.df_features is None:
        st.warning("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc!")
        return
    
    model_name = "RandomForest" if model_type == "RF" else "SVR"
    with st.spinner(f"ƒêang hu·∫•n luy·ªán m√¥ h√¨nh {model_name}..."):
        try:
            # Get feature columns
            # feature_cols = get_feature_columns()
            
            # Prepare data
            X_train, X_test, y_train, y_test, feature_cols = prepare_data_for_training(
                st.session_state.df_features,
                target_column='Target_Price',
                test_size=0.5
            )
            
            # L∆∞u danh s√°ch features v√†o session state ƒë·ªÉ d√πng khi d·ª± ƒëo√°n
            st.session_state.feature_cols = feature_cols
            
            if model_type == "RF":
                # Train RF
                model, scaler = train_layer1_model(X_train, y_train)
                save_model(model, L1_MODEL_PATH)
                save_model(scaler, L1_SCALER_PATH)
                
                # Store in session state
                st.session_state.model = model
                st.session_state.scaler = scaler
                st.session_state.model_trained = True
                
                # Add predictions to dataframe
                # df_clean = st.session_state.df_features.dropna(subset=feature_cols + ['Target_Price'])
                # X_all_scaled = scaler.transform(df_clean[feature_cols])

                # predictions = model.predict(X_all_scaled)
                # st.session_state.df_features.loc[df_clean.index, 'RF_Pred_Tomorrow'] = predictions
                # st.session_state.df_features['RF_Pred_Today'] = st.session_state.df_features['RF_Pred_Tomorrow'].shift(1)
            else:
                # Train SVR
                model, scaler = train_svr_model(X_train, y_train)
                save_model(model, L1_SVR_MODEL_PATH)
                save_model(scaler, L1_SVR_SCALER_PATH)
                
                # Store in session state
                st.session_state.svr_model = model
                st.session_state.svr_scaler = scaler
                st.session_state.svr_model_trained = True
                
                # Add predictions to dataframe
                # df_clean = st.session_state.df_features.dropna(subset=feature_cols + ['Target_Price'])
                # X_all_scaled = scaler.transform(df_clean[feature_cols])
                # predictions = model.predict(X_all_scaled)
                # st.session_state.df_features.loc[df_clean.index, 'SVR_Pred_Tomorrow'] = predictions
                # st.session_state.df_features['SVR_Pred_Today'] = st.session_state.df_features['SVR_Pred_Tomorrow'].shift(1)

            # Evaluate
            metrics = evaluate_model(model, scaler, X_test, y_test)
            # st.session_state.feature_cols = feature_cols
            
            # Display metrics
            st.success(f"Hu·∫•n luy·ªán m√¥ h√¨nh {model_name} th√†nh c√¥ng!")
            
            # Store metrics specifically
            if model_type == "RF":
                st.session_state.metrics = metrics
            else:
                st.session_state.svr_metrics = metrics
                
        except Exception as e:
            st.error(f"L·ªói khi hu·∫•n luy·ªán m√¥ h√¨nh {model_name}: {e}")
            import traceback
            st.error(traceback.format_exc())


def load_saved_model():
    """Load pre-trained models Layer 1 (RF & SVR)"""
    with st.spinner("ƒêang t·∫£i c√°c m√¥ h√¨nh Layer 1 ƒë√£ l∆∞u..."):
        try:
            # Load RF
            rf_model = load_model(L1_MODEL_PATH)
            rf_scaler = load_model(L1_SCALER_PATH)
            multi_models = load_model(L1_MULTI_MODELS_PATH)
            multi_scalers = load_model(L1_MULTI_SCALERS_PATH)
            
            # Load SVR
            svr_model = load_model(L1_SVR_MODEL_PATH)
            svr_scaler = load_model(L1_SVR_SCALER_PATH)
            
            # Feature columns are shared
            st.session_state.feature_cols = get_feature_columns()
            
            loaded_any = False
            
            if rf_model and rf_scaler:
                st.session_state.model = rf_model
                st.session_state.scaler = rf_scaler
                st.session_state.l1_multi_models = multi_models
                st.session_state.l1_multi_scalers = multi_scalers
                st.session_state.model_trained = True
                loaded_any = True
                st.info("‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh RandomForest")
                if multi_models is None:
                    st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y b·ªô 7 model RF (d·ª± b√°o 7 ng√†y).")
            
            if svr_model and svr_scaler:
                st.session_state.svr_model = svr_model
                st.session_state.svr_scaler = svr_scaler
                st.session_state.svr_model_trained = True
                loaded_any = True
                st.info("‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh SVR")
            
            if not loaded_any:
                st.warning("Kh√¥ng t√¨m th·∫•y b·∫•t k·ª≥ m√¥ h√¨nh Layer 1 n√†o ƒë√£ l∆∞u.")
            else:
                st.success("Qu√° tr√¨nh t·∫£i m√¥ h√¨nh ho√†n t·∫•t!")
            
        except Exception as e:
            st.error(f"L·ªói khi load m√¥ h√¨nh L1: {e}")


def delete_old_models():
    """X√≥a t·∫•t c·∫£ c√°c file model ƒë√£ l∆∞u trong th∆∞ m·ª•c models"""
    models_dir = './models/'
    try:
        if os.path.exists(models_dir):
            files = os.listdir(models_dir)
            if not files:
                st.info("Kh√¥ng c√≥ model n√†o ƒë·ªÉ x√≥a.")
                return
                
            for file in files:
                file_path = os.path.join(models_dir, file)
                if os.path.isfile(file_path):
                    os.remove(file_path)
            
            # Reset session state
            st.session_state.model = None
            st.session_state.scaler = None
            st.session_state.l1_multi_models = None
            st.session_state.l1_multi_scalers = None
            st.session_state.svr_model = None
            st.session_state.svr_scaler = None
            st.session_state.svr_model_trained = False
            st.session_state.model_trained = False
            if 'metrics' in st.session_state:
                del st.session_state.metrics
            if 'svr_metrics' in st.session_state:
                del st.session_state.svr_metrics
            if 'prediction' in st.session_state:
                del st.session_state.prediction
            if 'prediction_7days' in st.session_state:
                del st.session_state.prediction_7days
                
            st.success("ƒê√£ x√≥a t·∫•t c·∫£ model c≈© th√†nh c√¥ng!")
        else:
            st.info("Th∆∞ m·ª•c model kh√¥ng t·ªìn t·∫°i.")
    except Exception as e:
        st.error(f"L·ªói khi x√≥a model: {e}")


# Nh·∫•n d·ª± ƒëo√°n 1 ng√†y
def make_prediction():
    if st.session_state.df_features is None:
        st.warning("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc!")
        return
        
    if not st.session_state.model_trained and not st.session_state.svr_model_trained:
        st.warning("Ch∆∞a c√≥ m√¥ h√¨nh n√†o ƒë∆∞·ª£c hu·∫•n luy·ªán!")
        return
    
    with st.spinner("ƒêang t√≠nh to√°n d·ª± ƒëo√°n..."):
        try:
            df = st.session_state.df_features
            # Xu·∫•t d·ªØ li·ªáu ra file CSV ƒë·ªÉ ki·ªÉm tra
            df.to_csv('debug_df_features.csv', index=False)
            print(f"‚úÖ ƒê√£ xu·∫•t d·ªØ li·ªáu df_features ra file: debug_df_features.csv")
            
            latest_row = df.iloc[-1]
            print("\n" + "üöÄ " + "="*60)
            print("üîç DEBUG: CHI TI·∫æT D√íNG D·ªÆ LI·ªÜU CU·ªêI C√ôNG (LATEST ROW)")
            print("-" * 64)
            print(latest_row.to_string())
            print("-" * 64)
            print("üöÄ " + "="*60 + "\n")
            
            # Prepare feature data (handle NaNs) - CH·ªà L·∫§Y C√ÅC C·ªòT FEATURES (Lo·∫°i b·ªè Date)
            # L·∫•y d√≤ng cu·ªëi c√πng c·ªßa df (d√≤ng m·ªõi nh·∫•t ng∆∞·ªùi d√πng v·ª´a nh·∫≠p ho·∫∑c t·∫£i l√™n)
            feature_cols = st.session_state.feature_cols
            df_cleaned = df[feature_cols].copy().ffill().fillna(0)
            
            latest_features = df_cleaned.iloc[-1:].values
            pred_date = get_next_trading_date(latest_row['Date'])
            
            comparison_results = {}
            
            # Predict with RF if available
            if st.session_state.model_trained:
                pred_rf = create_prediction_with_confidence(
                    st.session_state.model, 
                    st.session_state.scaler,
                    latest_features
                )
                comparison_results['RF'] = {
                    'price': pred_rf['prediction'],
                    'lower': pred_rf['lower_bound'],
                    'upper': pred_rf['upper_bound']
                }
                
            # Predict with SVR if available
            if st.session_state.svr_model_trained:
                svr_pred_scaled = st.session_state.svr_model.predict(
                    st.session_state.svr_scaler.transform(latest_features)
                )[0]
                comparison_results['SVR'] = {
                    'price': svr_pred_scaled,
                    'lower': svr_pred_scaled * 0.98, # Theoretical interval
                    'upper': svr_pred_scaled * 1.02
                }
            
            st.session_state.prediction = {
                'date': pred_date,
                'current_price': latest_row['Price'],
                'results': comparison_results
            }
            
            # Th√™m c√°c ph√≠m ph·∫≥ng cho t√≠nh t∆∞∆°ng th√≠ch v·ªõi h√†m l∆∞u CSV (m·∫∑c ƒë·ªãnh l·∫•y RF)
            if 'RF' in comparison_results:
                st.session_state.prediction.update({
                    'predicted_price': comparison_results['RF']['price'],
                    'upper_bound': comparison_results['RF']['upper'],
                    'lower_bound': comparison_results['RF']['lower']
                })
            elif 'SVR' in comparison_results:
                st.session_state.prediction.update({
                    'predicted_price': comparison_results['SVR']['price'],
                    'upper_bound': comparison_results['SVR']['upper'],
                    'lower_bound': comparison_results['SVR']['lower']
                })
            
            st.success("ƒê√£ c·∫≠p nh·∫≠t d·ª± ƒëo√°n so s√°nh!")
            
        except Exception as e:
            st.error(f"L·ªói khi d·ª± ƒëo√°n: {e}")


def make_7day_prediction():
    """Make 7-day prediction using multi-horizon models (train on demand if needed)"""
    if st.session_state.df_features is None:
        st.warning("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc!")
        return

    # Check if multi-horizon models are already trained/loaded
    if st.session_state.l1_multi_models is None:
        with st.status("ƒêang hu·∫•n luy·ªán b·ªô 7 m√¥ h√¨nh chuy√™n bi·ªát cho d·ª± b√°o 7 ng√†y...", expanded=True) as status:
            try:
                st.write("D·ªØ li·ªáu ƒëang ƒë∆∞·ª£c chu·∫©n b·ªã...")
                feature_cols = get_feature_columns()
                
                st.write("B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán (quy tr√¨nh n√†y c√≥ th·ªÉ m·∫•t 1-2 ph√∫t)...")
                horizon_results = train_multi_horizon_models(st.session_state.df_features, feature_cols, days=7)
                
                multi_models = horizon_results['models']
                multi_scalers = horizon_results['scalers']
                
                # Save models
                save_model(multi_models, L1_MULTI_MODELS_PATH)
                save_model(multi_scalers, L1_MULTI_SCALERS_PATH)
                
                # Update session state
                st.session_state.l1_multi_models = multi_models
                st.session_state.l1_multi_scalers = multi_scalers
                st.session_state.feature_cols = feature_cols
                
                status.update(label="ƒê√£ hu·∫•n luy·ªán xong b·ªô 7 m√¥ h√¨nh!", state="complete", expanded=False)
            except Exception as e:
                status.update(label=f"L·ªói khi hu·∫•n luy·ªán: {e}", state="error")
                return

    with st.spinner("ƒêang t√≠nh to√°n d·ª± ƒëo√°n cho 7 ng√†y t·ªõi..."):
        try:
            # Prepare df for history
            df = st.session_state.df_features
            
            # Predict using the 7 individual models
            forecast_df = predict_multi_step_layer1(
                st.session_state.l1_multi_models,
                st.session_state.l1_multi_scalers,
                df,
                st.session_state.feature_cols,
                create_advanced_features,
                days=7
            )
            
            # Store in session state
            st.session_state.prediction_7days = forecast_df
            st.success("ƒê√£ ho√†n th√†nh d·ª± ƒëo√°n xu h∆∞·ªõng 7 ng√†y!")
            
        except Exception as e:
            st.error(f"L·ªói khi d·ª± ƒëo√°n 7 ng√†y: {e}")
            import traceback
            st.error(traceback.format_exc())


def update_csv_with_prediction(prediction_val):
    """Update the latest row in CSV with the prediction value"""
    try:
        df_csv = pd.read_csv(DISPLAY_DATA_PATH)
        # Assuming Date is unique and sorted
        df_csv.iloc[-1, df_csv.columns.get_loc('RF_Pred_Tomorrow')] = prediction_val
        df_csv.to_csv(DISPLAY_DATA_PATH, index=False)
        return True
    except Exception as e:
        st.error(f"L·ªói khi c·∫≠p nh·∫≠t CSV: {e}")
        return False


def display_dashboard():
    """Display main dashboard merging source data and saved predictions"""
    df = st.session_state.df_features
    
    # Load display data for predictions
    df_display = None
    if os.path.exists(DISPLAY_DATA_PATH):
        try:
            df_display = pd.read_csv(DISPLAY_DATA_PATH)
        except:
            pass
            
    # Latest data section - Only show latest date and single row
    st.header("D·ªØ li·ªáu m·ªõi nh·∫•t")
    
    latest = get_latest_row(df)
    
    # Display latest date prominently
    st.subheader(f"Ng√†y: {latest['Date'].strftime('%d/%m/%Y')}")
    
    # Metrics in one row
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric(
            "Gi√° ƒë√≥ng c·ª≠a",
            f"${format_number(latest['Price'])}",
            f"{format_number(latest['Return_1d'] if 'Return_1d' in latest else 0, 2)}%"
        )
    
    with col2:
        st.metric("Gi√° m·ªü c·ª≠a", f"${format_number(latest['Open'])}")
    
    with col3:
        st.metric("Gi√° cao nh·∫•t", f"${format_number(latest['High'])}")
    
    with col4:
        st.metric("Gi√° th·∫•p nh·∫•t", f"${format_number(latest['Low'])}")
    
    with col5:
        st.metric("Kh·ªëi l∆∞·ª£ng", f"{int(latest['Vol']):,}")
    
    # Show only the latest row in a clean table
    st.subheader("Chi ti·∫øt d√≤ng d·ªØ li·ªáu m·ªõi nh·∫•t")
    
    # Determine which columns to show as requested by user
    base_cols = ['Date', 'Price', 'Open', 'High', 'Low', 'Vol']
    latest_row_df = df[base_cols].tail(1).copy()

    # Add prediction columns from DISPLAY_DATA_PATH if available
    if df_display is not None and not df_display.empty:
        last_display = df_display.iloc[-1]
        if 'RF_Pred_Tomorrow' in df_display.columns:
            latest_row_df['RF_Pred_Tomorrow'] = last_display['RF_Pred_Tomorrow']
        if 'RF_Pred_Today' in df_display.columns:
            latest_row_df['RF_Pred_Today'] = last_display['RF_Pred_Today']
        if 'SVR_Pred_Tomorrow' in df_display.columns:
            latest_row_df['SVR_Pred_Tomorrow'] = last_display['SVR_Pred_Tomorrow']
        if 'SVR_Pred_Today' in df_display.columns:
            latest_row_df['SVR_Pred_Today'] = last_display['SVR_Pred_Today']

    latest_row_df['Date'] = latest_row_df['Date'].dt.strftime('%d/%m/%Y')
    
    # Format numeric columns
    price_cols = ['Price', 'Open', 'High', 'Low', 'RF_Pred_Tomorrow', 'RF_Pred_Today', 'SVR_Pred_Tomorrow', 'SVR_Pred_Today']
    for col in price_cols:
        if col in latest_row_df.columns:
            latest_row_df[col] = latest_row_df[col].apply(lambda x: f"${x:.4f}" if pd.notna(x) else "N/A")
    
    if 'Vol' in latest_row_df.columns:
        latest_row_df['Vol'] = latest_row_df['Vol'].apply(lambda x: f"{int(x):,}" if pd.notna(x) else "N/A")
    
    st.dataframe(latest_row_df, use_container_width=True, hide_index=True)
    
    st.markdown("---")

    # Hi·ªÉn th·ªã form nh·∫≠p d·ªØ li·ªáu th·ªß c√¥ng n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
    if st.session_state.show_manual_input:
        display_manual_input_form()
        st.markdown("---")
    
    # Display prediction 1-day if available
    if 'prediction' in st.session_state:
        display_prediction_inline()
        st.markdown("---")
    
    # Display 7-day prediction if available
    if 'prediction_7days' in st.session_state:
        display_7day_prediction_inline()
        st.markdown("---")
    
    # Charts section
    st.header("Ph√¢n t√≠ch gi√°")
    
    tab1, tab2, tab3, tab4 = st.tabs(["L·ªãch s·ª≠ gi√°", "N·∫øn Nh·∫≠t", "Kh·ªëi l∆∞·ª£ng", "Ch·ªâ s·ªë k·ªπ thu·∫≠t"])
    
    with tab1:
        fig = plot_price_history(df, n_days=100)
        st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        fig = plot_candlestick(df, n_days=60)
        st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        fig = plot_volume(df, n_days=60)
        st.plotly_chart(fig, use_container_width=True)
    
    with tab4:
        fig = plot_technical_indicators(df, n_days=60)
        st.plotly_chart(fig, use_container_width=True)
    
    # Model performance
    # Model performance comparison
    if (st.session_state.model_trained and 'metrics' in st.session_state) or \
       (st.session_state.svr_model_trained and 'svr_metrics' in st.session_state):
        
        st.markdown("---")
        st.header("üìä So s√°nh hi·ªáu su·∫•t m√¥ h√¨nh")
        
        m_tabs = []
        if st.session_state.model_trained: m_tabs.append("üå≤ RandomForest")
        if st.session_state.svr_model_trained: m_tabs.append("üìà SVR")
        
        if m_tabs:
            tabs = st.tabs(m_tabs)
            
            tab_idx = 0
            if st.session_state.model_trained:
                with tabs[tab_idx]:
                    if 'metrics' in st.session_state and st.session_state.metrics is not None:
                        metrics = st.session_state.metrics
                        c1, c2, c3, c4 = st.columns(4)
                        c1.metric("MAE", f"{metrics['MAE']:.6f}")
                        c2.metric("RMSE", f"{metrics['RMSE']:.6f}")
                        c3.metric("R¬≤ Score", f"{metrics['R2']:.4f}")
                        c4.metric("H∆∞·ªõng", f"{metrics['Direction_Accuracy']:.2f}%")
                    else:
                        st.info("Ch∆∞a c√≥ th√¥ng tin ƒë√°nh gi√° m√¥ h√¨nh RF. Vui l√≤ng hu·∫•n luy·ªán l·∫°i ƒë·ªÉ xem chi ti·∫øt.")
                    
                    if st.checkbox("Feature Importance (RF)", key="show_fi_rf"):
                        feature_imp = get_feature_importance(st.session_state.model, st.session_state.feature_cols, top_n=15)
                        st.plotly_chart(plot_feature_importance(feature_imp), use_container_width=True)
                tab_idx += 1
                
            if st.session_state.svr_model_trained:
                with tabs[tab_idx]:
                    if 'svr_metrics' in st.session_state and st.session_state.svr_metrics is not None:
                        metrics = st.session_state.svr_metrics
                        c1, c2, c3, c4 = st.columns(4)
                        c1.metric("MAE", f"{metrics['MAE']:.6f}")
                        c2.metric("RMSE", f"{metrics['RMSE']:.6f}")
                        c3.metric("R¬≤ Score", f"{metrics['R2']:.4f}")
                        c4.metric("H∆∞·ªõng", f"{metrics['Direction_Accuracy']:.2f}%")
                    else:
                        st.info("Ch∆∞a c√≥ th√¥ng tin ƒë√°nh gi√° m√¥ h√¨nh SVR. Vui l√≤ng hu·∫•n luy·ªán l·∫°i ƒë·ªÉ xem chi ti·∫øt.")
                    st.info("üí° SVR kh√¥ng h·ªó tr·ª£ t√≠nh to√°n tr·ª±c ti·∫øp Feature Importance nh∆∞ RandomForest.")


def display_prediction_inline():
    """Display prediction results inline with comparison"""
    if 'prediction' not in st.session_state:
        return
    
    pred = st.session_state.prediction
    results = pred['results']
    
    st.header("K·∫øt qu·∫£ d·ª± ƒëo√°n so s√°nh")
    
    # Display cards for each model
    cols = st.columns(len(results))
    
    for i, (m_type, data) in enumerate(results.items()):
        with cols[i]:
            bg_gradient = "linear-gradient(135deg, #667eea 0%, #764ba2 100%)" if m_type == "RF" else "linear-gradient(135deg, #02aab0 0%, #00cdac 100%)"
            title = "üå≤ RandomForest" if m_type == "RF" else "üìà SVR"
            
            change = data['price'] - pred['current_price']
            change_pct = (change / pred['current_price']) * 100
            color = "#00ff88" if change >= 0 else "#ff5555"
            arrow = "‚Üë" if change >= 0 else "‚Üì"

            st.markdown(f"""
            <div style="background: {bg_gradient}; padding: 2rem; border-radius: 20px; text-align: center; color: white; box-shadow: 0 10px 20px rgba(0,0,0,0.2);">
                <h3 style="margin-bottom: 0.5rem;">{title}</h3>
                <p style="font-size: 0.9rem; opacity: 0.8;">{pred['date'].strftime('%d/%m/%Y')}</p>
                <h1 style="font-size: 2.5rem; margin: 1rem 0;">${format_number(data['price'])}</h1>
                <div style="background: rgba(255,255,255,0.1); padding: 0.5rem; border-radius: 10px;">
                    <span style="color: {color}; font-weight: bold; font-size: 1.1rem;">{arrow} {format_number(abs(change_pct), 2)}%</span>
                </div>
                <p style="margin-top: 1rem; font-size: 0.8rem; opacity: 0.7;">Kho·∫£ng tin c·∫≠y: ${format_number(data['lower'])} - ${format_number(data['upper'])}</p>
            </div>
            """, unsafe_allow_html=True)

    # Save action if RF is available
    if 'RF' in results:
        st.markdown("<br>", unsafe_allow_html=True)
        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            if st.button("L∆∞u d·ª± ƒëo√°n RF v√†o CSV", use_container_width=True):
                save_prediction_to_csv()


def display_7day_prediction_inline():
    """Display 7-day forecast results with table and chart"""
    st.header("D·ª± ƒëo√°n xu h∆∞·ªõng 7 ng√†y")
    
    forecast_df = st.session_state.prediction_7days
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("B·∫£ng d·ª± ki·∫øn")
        display_df = forecast_df.copy()
        display_df['Date'] = display_df['Date'].dt.strftime('%d/%m/%Y')
        display_df['Predicted_Price'] = display_df['Predicted_Price'].apply(lambda x: f"${x:.4f}")
        st.dataframe(display_df, use_container_width=True, hide_index=True)
    
    with col2:
        st.subheader("Bi·ªÉu ƒë·ªì xu h∆∞·ªõng")
        
        # Th√™m gi√° hi·ªán t·∫°i v√†o bi·ªÉu ƒë·ªì ƒë·ªÉ th·∫•y s·ª± k·∫øt n·ªëi
        df_hist = st.session_state.df_features.tail(5)
        
        fig = go.Figure()
        
        # ƒê∆∞·ªùng gi√° l·ªãch s·ª≠ ng·∫Øn
        fig.add_trace(go.Scatter(
            x=df_hist['Date'], y=df_hist['Price'],
            mode='lines+markers', name='Th·ª±c t·∫ø',
            line=dict(color='blue')
        ))
        
        # ƒê∆∞·ªùng d·ª± ƒëo√°n
        # K·∫øt n·ªëi ƒëi·ªÉm cu·ªëi th·ª±c t·∫ø v·ªõi ƒëi·ªÉm ƒë·∫ßu d·ª± ƒëo√°n
        x_pred = [df_hist['Date'].iloc[-1]] + forecast_df['Date'].tolist()
        y_pred = [df_hist['Price'].iloc[-1]] + forecast_df['Predicted_Price'].tolist()
        
        fig.add_trace(go.Scatter(
            x=x_pred, y=y_pred,
            mode='lines+markers', name='D·ª± ƒëo√°n (7 ng√†y)',
            line=dict(color='orange', dash='dash')
        ))
        
        fig.update_layout(
            template='plotly_white',
            margin=dict(l=20, r=20, t=20, b=20),
            height=400,
            xaxis_title="Ng√†y",
            yaxis_title="Gi√° XRP ($)"
        )
        
        st.plotly_chart(fig, use_container_width=True)


def save_prediction_to_csv():
    """Save prediction to CSV file"""
    if 'prediction' not in st.session_state:
        st.warning("Kh√¥ng c√≥ d·ª± ƒëo√°n ƒë·ªÉ l∆∞u!")
        return
    
    pred = st.session_state.prediction
    is_new_prediction = pred.get('is_new_prediction', True)
    
    if is_new_prediction:
        # Check if we should update an existing row (where RF_Pred_Tomorrow was NaN)
        # or append a completely new row.
        # If the prediction date matches the "tomorrow" of the last row in df
        df = st.session_state.df_features
        latest_date = df.iloc[-1]['Date']
        
        # If the prediction is indeed for the 'tomorrow' of the last existing row
        # we update that row's RF_Pred_Tomorrow column
        success = update_csv_with_prediction(pred['predicted_price'])
        
        if success:
            st.success(f"ƒê√£ c·∫≠p nh·∫≠t d·ª± ƒëo√°n cho ng√†y {pred['date'].strftime('%d/%m/%Y')} v√†o d·ªØ li·ªáu hi·ªán c√≥!")
            load_and_process_data(target_path=DISPLAY_DATA_PATH) # Reload t·ª´ file v·ª´a l∆∞u
            st.rerun() # L√†m m·ªõi giao di·ªán ngay l·∫≠p t·ª©c
        else:
            # Fallback to append if update fails or logic dictates
            prediction_data = {
                'Date': pred['date'],
                'Price': pred['predicted_price'],
                'Open': pred['predicted_price'],
                'High': pred['upper_bound'],
                'Low': pred['lower_bound'],
                'Vol': 0
            }
            if append_prediction_to_csv(DISPLAY_DATA_PATH, prediction_data):
                st.success("ƒê√£ th√™m d√≤ng d·ª± ƒëo√°n m·ªõi v√†o CSV!")
                load_and_process_data(target_path=DISPLAY_DATA_PATH)
                st.rerun()
            else:
                st.error("L∆∞u d·ª± ƒëo√°n th·∫•t b·∫°i")
    else:
        st.info("D·ª± ƒëo√°n n√†y ƒë√£ t·ªìn t·∫°i trong t·ªáp d·ªØ li·ªáu.")



def display_manual_input_form():
    """Hi·ªÉn th·ªã form nh·∫≠p d·ªØ li·ªáu th·ª±c t·∫ø cho ng√†y ti·∫øp theo"""
    df = st.session_state.df_features
    latest_date = df.iloc[-1]['Date']
    next_date = get_next_trading_date(latest_date)
    
    st.subheader(f"Nh·∫≠p d·ªØ li·ªáu th·ª±c t·∫ø cho ng√†y: {next_date.strftime('%d/%m/%Y')}")
    
    with st.form("manual_input_form"):
        col1, col2, col3 = st.columns(3)
        with col1:
            price = st.number_input("Price (Gi√° ƒë√≥ng c·ª≠a)", value=float(df.iloc[-1]['Price']), format="%.4f")
            open_p = st.number_input("Open (Gi√° m·ªü c·ª≠a)", value=float(df.iloc[-1]['Price']), format="%.4f")
        with col2:
            high = st.number_input("High (Gi√° cao nh·∫•t)", value=float(df.iloc[-1]['Price']), format="%.4f")
            low = st.number_input("Low (Gi√° th·∫•p nh·∫•t)", value=float(df.iloc[-1]['Price']), format="%.4f")
        with col3:
            vol = st.number_input("Volume (Kh·ªëi l∆∞·ª£ng)", value=int(df.iloc[-1]['Vol']), step=1000)
            
        submit = st.form_submit_button("D·ª± ƒëo√°n cho ng√†y ti·∫øp theo")
        
        if submit:
            handle_manual_input_submission(next_date, price, open_p, high, low, vol)
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£ v·ª´a d·ª± ƒëo√°n n·∫øu c√≥
    if 'last_manual_result' in st.session_state:
        st.markdown("#### K·∫øt qu·∫£ d·ª± ƒëo√°n cho d√≤ng d·ªØ li·ªáu v·ª´a nh·∫≠p:")
        st.dataframe(st.session_state.last_manual_result, use_container_width=True, hide_index=True)


def handle_manual_input_submission(date, price, open_p, high, low, vol):
    """X·ª≠ l√Ω l∆∞u d·ªØ li·ªáu th·ª±c t·∫ø v√† T·∫§T C·∫¢ c√°c ch·ªâ s·ªë k·ªπ thu·∫≠t v√†o CSV"""
    try:
        # 1. Load d·ªØ li·ªáu hi·ªán t·∫°i ch·ªâ l·∫•y c√°c c·ªôt g·ªëc ƒë·ªÉ tr√°nh b·ªã l·∫∑p c·ªôt features c≈©
        df_raw = load_data(DISPLAY_DATA_PATH)
        base_cols = ['Date', 'Price', 'Open', 'High', 'Low', 'Vol']
        df_base = df_raw[base_cols].copy()
        
        # 2. Th√™m d√≤ng m·ªõi v√†o base data
        new_row = pd.DataFrame([{
            'Date': date,
            'Price': price,
            'Open': open_p,
            'High': high,
            'Low': low,
            'Vol': vol
        }])
        df_base = pd.concat([df_base, new_row], ignore_index=True)
        
        # 3. T√≠nh to√°n l·∫°i TO√ÄN B·ªò features tr√™n d·ªØ li·ªáu ƒë√£ n·ªëi
        df_all_features = create_advanced_features(df_base)
        
        # ƒê·∫£m b·∫£o RF_Pred_Today ƒë∆∞·ª£c t√≠nh t·ª´ RF_Pred_Tomorrow c·ªßa ng√†y tr∆∞·ªõc ƒë√≥ (n·∫øu c√≥)
        if 'RF_Pred_Tomorrow' in df_raw.columns:
            # Copy c·ªôt d·ª± b√°o c≈© sang ƒë·ªÉ kh√¥ng b·ªã m·∫•t d·ªØ li·ªáu l·ªãch s·ª≠
            df_all_features['RF_Pred_Tomorrow'] = df_raw['RF_Pred_Tomorrow']
            df_all_features.loc[df_all_features.index[-1], 'RF_Pred_Tomorrow'] = np.nan
        
        # 4. Th·ª±c hi·ªán d·ª± b√°o RF_Pred_Tomorrow cho d√≤ng v·ª´a th√™m
        if st.session_state.model is not None and st.session_state.scaler is not None:
            feature_cols = get_feature_columns()
            # X·ª≠ l√Ω NaN cho features tr∆∞·ªõc khi d·ª± b√°o
            df_for_pred = df_all_features[feature_cols].copy().ffill().fillna(0)
            latest_features = df_for_pred.iloc[-1:].values
            
            # D·ª± b√°o gi√° cho ng√†y ti·∫øp theo
            pred_val = predict_next_day_layer1(st.session_state.model, st.session_state.scaler, latest_features)
            df_all_features.loc[df_all_features.index[-1], 'RF_Pred_Tomorrow'] = pred_val
            
        # 5. C·∫≠p nh·∫≠t RF_Pred_Today (L·∫•y d·ª± b√°o c·ªßa ng√†y tr∆∞·ªõc ƒë√≥ g√°n cho h√¥m nay)
        if 'RF_Pred_Tomorrow' in df_all_features.columns:
            df_all_features['RF_Pred_Today'] = df_all_features['RF_Pred_Tomorrow'].shift(1)
            
        # 6. L∆∞u TO√ÄN B·ªò dataframe v·ªõi h√†ng trƒÉm c·ªôt v√†o CSV
        # Chuy·ªÉn Date sang string YYYY-MM-DD tr∆∞·ªõc khi l∆∞u
        df_save = df_all_features.copy()
        df_save['Date'] = df_save['Date'].dt.strftime('%Y-%m-%d')
        df_save.to_csv(DISPLAY_DATA_PATH, index=False)
        
        # 7. C·∫≠p nh·∫≠t giao di·ªán
        st.session_state.df_features = df_all_features
        
        # L∆∞u d√≤ng k·∫øt qu·∫£ ƒë·ªÉ hi·ªÉn th·ªã ngay d∆∞·ªõi form
        result_display = df_all_features.tail(1).copy()
        result_display['Date'] = result_display['Date'].dt.strftime('%d/%m/%Y')
        for col in result_display.columns:
            if col != 'Date' and col != 'Vol':
                result_display[col] = result_display[col].apply(lambda x: f"${x:.4f}" if pd.notna(x) else "N/A")
        
        st.session_state.last_manual_result = result_display
        st.success(f"ƒê√£ c·∫≠p nh·∫≠t to√†n b·ªô ch·ªâ s·ªë v√† d·ª± b√°o v√†o file CSV!")
        st.rerun()
        
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu: {e}")
        import traceback
        st.error(traceback.format_exc())


def display_layer2_content():
    """Display Layer 2 (Within-day prediction) content"""
    st.header("üéØ D·ª± ƒëo√°n gi√° trong ng√†y (Layer 2)")
    
    if st.session_state.df_features is None:
        st.info("Vui l√≤ng t·∫£i d·ªØ li·ªáu ·ªü Sidebar tr∆∞·ªõc.")
        return

    # Train/Load buttons for L2
    col1, col2 = st.columns(2)
    with col1:
        if st.button("Train m√¥ h√¨nh Layer 2", use_container_width=True, disabled=not st.session_state.model_trained):
            train_layer2_logic()
    with col2:
        if st.button("Load Layer 2 model", use_container_width=True):
            load_l2_model()

    st.markdown("---")

    # Prediction Section
    st.subheader("üîÆ D·ª± ƒëo√°n gi√° ch·ªët phi√™n tr·ª±c tuy·∫øn")
    
    # 1. Get Base Predictions from Layer 1 for the TARGET day
    latest_row = st.session_state.df_features.iloc[-1]
    last_date = latest_row['Date']
    target_date = get_next_trading_date(last_date)
    
    # Check if we have fresh predictions
    l1_rf_target = None
    l1_svr_target = None
    
    # Try getting from row first
    if 'RF_Pred_Tomorrow' in latest_row and pd.notna(latest_row['RF_Pred_Tomorrow']):
        l1_rf_target = latest_row['RF_Pred_Tomorrow']
    if 'SVR_Pred_Tomorrow' in latest_row and pd.notna(latest_row['SVR_Pred_Tomorrow']):
        l1_svr_target = latest_row['SVR_Pred_Tomorrow']
        
    # Overwrite/fill from session if user just clicked predict
    if 'prediction' in st.session_state:
        if st.session_state.prediction['date'].date() == target_date.date():
            results = st.session_state.prediction['results']
            if 'RF' in results: l1_rf_target = results['RF']['price']
            if 'SVR' in results: l1_svr_target = results['SVR']['price']

    if l1_rf_target is None or l1_svr_target is None:
        st.warning(f"‚ö†Ô∏è Ch∆∞a c√≥ ƒë·ªß d·ª± ƒëo√°n Layer 1 (RF & SVR) cho ng√†y {target_date.strftime('%d/%m/%Y')}. Vui l√≤ng qua Tab Layer 1 hu·∫•n luy·ªán v√† d·ª± ƒëo√°n c·∫£ 2 m√¥ h√¨nh tr∆∞·ªõc.")
        return

    st.success(f"üìÖ M·ª•c ti√™u: D·ª± ƒëo√°n gi√° ƒê√≥ng c·ª≠a cho ng√†y **{target_date.strftime('%d/%m/%Y')}**")
    col_l1a, col_l1b = st.columns(2)
    col_l1a.info(f"üí° RF L1: **${l1_rf_target:.4f}**")
    col_l1b.info(f"üí° SVR L1: **${l1_svr_target:.4f}**")

    # 2. User Input
    with st.form("layer2_form"):
        st.write(f"Nh·∫≠p d·ªØ li·ªáu th·ªã tr∆∞·ªùng th·ª±c t·∫ø c·ªßa ng√†y {target_date.strftime('%d/%m/%Y')}:")
        col1, col2 = st.columns(2)
        with col1:
            open_price = st.number_input("Gi√° m·ªü c·ª≠a (Open)", value=None, placeholder="Nh·∫≠p gi√° m·ªü c·ª≠a...", format="%.4f")
            high_price = st.number_input("Gi√° cao nh·∫•t (High)", value=None, placeholder="Nh·∫≠p gi√° cao nh·∫•t...", format="%.4f")
        with col2:
            current_vol = st.number_input("Kh·ªëi l∆∞·ª£ng d·ª± ki·∫øn (Volume)", value=None, placeholder="Nh·∫≠p kh·ªëi l∆∞·ª£ng d·ª± ki·∫øn...", format="%.0f")
            low_price = st.number_input("Gi√° th·∫•p nh·∫•t (Low)", value=None, placeholder="Nh·∫≠p gi√° th·∫•p nh·∫•t...", format="%.4f")
        
        submit = st.form_submit_button("üî• T√≠nh to√°n gi√° ch·ªët phi√™n (Layer 2)")

    if submit:
        if any(v is None for v in [open_price, high_price, low_price, current_vol]):
            st.error("Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß gi√° Open, High, Low v√† Volume c·ªßa ng√†y h√¥m nay!")
        elif not (st.session_state.l2_ridge_model_trained or st.session_state.l2_svr_model_trained):
            st.error("Vui l√≤ng train Layer 2 t·∫°i Tab n√†y tr∆∞·ªõc!")
        else:
            try:
                # Prepare L2 input: [Open, High, Low, Vol, RF_Pred_Today, SVR_Pred_Today]
                l2_input = np.array([[open_price, high_price, low_price, current_vol, l1_rf_target, l1_svr_target]])
                
                res_col1, res_col2 = st.columns(2)
                
                if st.session_state.l2_ridge_model_trained:
                    pred_ridge = predict_layer2(st.session_state.l2_ridge_model, st.session_state.l2_ridge_scaler, l2_input)
                    with res_col1:
                        st.markdown(f"""
                        <div class="prediction-box" style="background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);">
                            <h3 style="color: white; margin-bottom: 0px;">L2: Ridge (Th·ªëng k√™)</h3>
                            <h1 style="color: white; font-size: 3rem; margin-top: 10px;">${pred_ridge:.4f}</h1>
                            <p style="color: white; font-size: 0.9rem;">(D·ª±a tr√™n O-H-L-V & L1 Hybrid)</p>
                        </div>
                        """, unsafe_allow_html=True)
                
                if st.session_state.l2_svr_model_trained:
                    pred_l2_svr = predict_layer2(st.session_state.l2_svr_model, st.session_state.l2_svr_scaler, l2_input)
                    with res_col2:
                        st.markdown(f"""
                        <div class="prediction-box" style="background: linear-gradient(135deg, #FF512F 0%, #DD2476 100%);">
                            <h3 style="color: white; margin-bottom: 0px;">L2: SVR (M√°y h·ªçc)</h3>
                            <h1 style="color: white; font-size: 3rem; margin-top: 10px;">${pred_l2_svr:.4f}</h1>
                            <p style="color: white; font-size: 0.9rem;">(D·ª±a tr√™n O-H-L-V & L1 Hybrid)</p>
                        </div>
                        """, unsafe_allow_html=True)
                
            except Exception as e:
                st.error(f"L·ªói d·ª± ƒëo√°n L2: {e}")

def train_layer2_logic():
    """Train Layer 2 (Ridge & SVR) using both L1 predictions"""
    with st.spinner("ƒêang hu·∫•n luy·ªán Layer 2..."):
        try:
            df = st.session_state.df_features.copy()
            # Features are: Open, High, Low, Vol, RF_Pred_Today, SVR_Pred_Today
            l2_features = ['Open', 'High', 'Low', 'Vol', 'RF_Pred_Today', 'SVR_Pred_Today']
            target = 'Price'
            
            # Prepare data
            df_l2 = df.dropna(subset=l2_features + [target])
            X = df_l2[l2_features]
            y = df_l2[target]
            
            # Split
            split_idx = int(len(X) * 0.8)
            X_train, X_test = X[:split_idx], X[split_idx:]
            y_train, y_test = y[:split_idx], y[split_idx:]
            
            # Train Ridge
            ridge_model, ridge_scaler = train_layer2_model(X_train, y_train)
            save_model(ridge_model, L2_RIDGE_MODEL_PATH)
            save_model(ridge_scaler, L2_RIDGE_SCALER_PATH)
            
            # Train SVR for L2
            svr_model, svr_scaler = train_svr_model(X_train, y_train)
            save_model(svr_model, L2_SVR_MODEL_PATH)
            save_model(svr_scaler, L2_SVR_SCALER_PATH)
            
            st.session_state.l2_ridge_model = ridge_model
            st.session_state.l2_ridge_scaler = ridge_scaler
            st.session_state.l2_ridge_model_trained = True
            
            st.session_state.l2_svr_model = svr_model
            st.session_state.l2_svr_scaler = svr_scaler
            st.session_state.l2_svr_model_trained = True
            
            st.success(f"ƒê√£ train Layer 2 (Ridge & SVR) th√†nh c√¥ng!")
            
        except Exception as e:
            st.error(f"L·ªói khi train L2: {e}")


def load_l2_model():
    """Load Layer 2 models"""
    with st.spinner("ƒêang t·∫£i c√°c m√¥ h√¨nh Layer 2..."):
        try:
            # Load Ridge
            ridge_model = load_model(L2_RIDGE_MODEL_PATH)
            ridge_scaler = load_model(L2_RIDGE_SCALER_PATH)
            if ridge_model and ridge_scaler:
                st.session_state.l2_ridge_model = ridge_model
                st.session_state.l2_ridge_scaler = ridge_scaler
                st.session_state.l2_ridge_model_trained = True
                st.info("‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh L2 Ridge")
                
            # Load SVR
            svr_model = load_model(L2_SVR_MODEL_PATH)
            svr_scaler = load_model(L2_SVR_SCALER_PATH)
            if svr_model and svr_scaler:
                st.session_state.l2_svr_model = svr_model
                st.session_state.l2_svr_scaler = svr_scaler
                st.session_state.l2_svr_model_trained = True
                st.info("‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh L2 SVR")
                
            st.success("T·∫£i m√¥ h√¨nh Layer 2 ho√†n t·∫•t!")
        except Exception as e:
            st.error(f"L·ªói khi load L2 models: {e}")


def display_layer3_content():
    """Hi·ªÉn th·ªã n·ªôi dung cho Layer 3 (LSTM)"""
    st.subheader("Layer 3: D·ª± b√°o chu·ªói th·ªùi gian b·∫±ng Deep Learning (LSTM)")
    
    # Cho ph√©p ch·ªçn file CSV ri√™ng cho Layer 3
    st.markdown("### üìÅ Ch·ªçn d·ªØ li·ªáu cho Layer 3")
    l3_file = st.file_uploader("T·∫£i l√™n file CSV (V√≠ d·ª•: ETHUSDT.csv)", type=['csv'])
    
    if l3_file is not None:
        if st.button("S·ª≠ d·ª•ng file ƒë√£ t·∫£i l√™n cho Layer 3"):
            load_l3_custom_data(l3_file)
            
    st.markdown("---")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        if st.button("X·ª≠ l√Ω d·ªØ li·ªáu L3", use_container_width=True):
            prepare_l3_features()
    with col2:
        if st.button("Train m√¥ h√¨nh L3", use_container_width=True):
            train_l3_model()
    with col3:
        if st.button("Load L3 model", use_container_width=True):
            load_l3_model()
    with col4:
        if st.button("D·ª± b√°o LSTM (7 ng√†y)", use_container_width=True, disabled=not st.session_state.l3_model_trained):
            make_l3_prediction()

    st.markdown("---")
    
    if 'l3_prediction' in st.session_state:
        display_l3_prediction_results()
    else:
        st.info("S·ª≠ d·ª•ng LSTM ƒë·ªÉ d·ª± b√°o bi·∫øn ƒë·ªông gi√° trong 7 ng√†y t·ªõi d·ª±a tr√™n 30 ng√†y l·ªãch s·ª≠.")
        
    if st.checkbox("Hi·ªÉn th·ªã ki·∫øn tr√∫c m√¥ h√¨nh LSTM"):
        st.code("""
        Model: Sequential
        Layer 1: LSTM (64 units, return_sequences=True)
        Layer 2: Dropout (0.2)
        Layer 3: LSTM (32 units)
        Layer 4: Dropout (0.2)
        Layer 5: Dense (7 units - forecast window)
        Optimizer: Adam (lr=0.001)
        Loss: MSE
        """)

def load_l3_custom_data(uploaded_file):
    """Load d·ªØ li·ªáu t·ª´ file upload cho Layer 3"""
    try:
        df = pd.read_csv(uploaded_file)
        # Standardize columns
        if 'Date' in df.columns:
            df['Date'] = pd.to_datetime(df['Date'])
        
        # Mapping common column names if needed
        col_map = {
            'Close': 'Price',
            'Volume': 'Vol'
        }
        df = df.rename(columns=col_map)
        
        # Basic requirements
        required = ['Date', 'Price', 'Open', 'High', 'Low', 'Vol']
        if all(col in df.columns for col in required):
            st.session_state.df_l3_raw = df[required]
            st.success(f"ƒê√£ t·∫£i d·ªØ li·ªáu t·ª´ {uploaded_file.name} cho Layer 3!")
            st.dataframe(df.head())
        else:
            st.error(f"File CSV thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: {required}")
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω file: {e}")

def prepare_l3_features():
    """T·∫°o features cho LSTM"""
    # ∆Øu ti√™n s·ª≠ d·ª•ng d·ªØ li·ªáu ri√™ng c·ªßa L3 n·∫øu c√≥, n·∫øu kh√¥ng l·∫•y t·ª´ main df
    if 'df_l3_raw' in st.session_state:
        df = st.session_state.df_l3_raw.copy()
    elif st.session_state.df_features is not None:
        df = st.session_state.df_features[['Date', 'Price', 'Open', 'High', 'Low', 'Vol']]
    else:
        st.error("Vui l√≤ng t·∫£i d·ªØ li·ªáu ho·∫∑c ch·ªçn file CSV!")
        return
        
    with st.spinner("ƒêang t√≠nh to√°n technical indicators cho LSTM..."):
        try:
            df_l3 = create_lstm_features(df)
            st.session_state.df_l3 = df_l3
            st.success(f"ƒê√£ chu·∫©n b·ªã {len(df_l3.columns)} features cho LSTM!")
            st.dataframe(df_l3.tail(5))
        except Exception as e:
            st.error(f"L·ªói: {e}")

def train_l3_model():
    """Train LSTM model"""
    if 'df_l3' not in st.session_state:
        prepare_l3_features()
        
    df = st.session_state.df_l3.copy()
    feature_cols = ['Open', 'High', 'Low', 'Price', 'Vol', 'VVR', 'VWAP', 
                    'Lag_1', 'Lag_2', 'Lag_3', 'Lag_5', 'Lag_7', 
                    'Price_Change', 'Volatility', 'MA5', 'MA10']
    
    df_clean = df.dropna(subset=feature_cols)
    
    with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh LSTM (Deep Learning)..."):
        try:
            X, y, scaler, target_scaler = prepare_lstm_data(df_clean, feature_cols)
            
            # Split
            n = len(X)
            split = int(n * 0.9)
            X_train, y_train = X[:split], y[:split]
            
            model = train_lstm_model(X_train, y_train)
            
            # Save
            model.save(L3_MODEL_PATH)
            save_model(scaler, L3_SCALER_PATH)
            save_model(target_scaler, L3_TARGET_SCALER_PATH)
            
            st.session_state.l3_model = model
            st.session_state.l3_scaler = scaler
            st.session_state.l3_target_scaler = target_scaler
            st.session_state.l3_model_trained = True
            st.session_state.l3_feature_cols = feature_cols
            
            st.success("Hu·∫•n luy·ªán Layer 3 (LSTM) th√†nh c√¥ng!")
        except Exception as e:
            st.error(f"L·ªói khi train LSTM: {e}")

def load_l3_model():
    """Load pre-trained LSTM model"""
    with st.spinner("ƒêang load m√¥ h√¨nh LSTM..."):
        try:
            from tensorflow.keras.models import load_model as load_keras_model
            if os.path.exists(L3_MODEL_PATH):
                st.session_state.l3_model = load_keras_model(L3_MODEL_PATH)
                st.session_state.l3_scaler = load_model(L3_SCALER_PATH)
                st.session_state.l3_target_scaler = load_model(L3_TARGET_SCALER_PATH)
                st.session_state.l3_model_trained = True
                st.session_state.l3_feature_cols = ['Open', 'High', 'Low', 'Price', 'Vol', 'VVR', 'VWAP', 
                                                'Lag_1', 'Lag_2', 'Lag_3', 'Lag_5', 'Lag_7', 
                                                'Price_Change', 'Volatility', 'MA5', 'MA10']
                st.success("ƒê√£ load Layer 3 th√†nh c√¥ng!")
            else:
                st.warning("Kh√¥ng t√¨m th·∫•y t·ªáp m√¥ h√¨nh Layer 3.")
        except Exception as e:
            st.error(f"L·ªói: {e}")

def make_l3_prediction():
    """D·ª± b√°o 7 ng√†y t·ªõi b·∫±ng LSTM"""
    if not st.session_state.l3_model_trained:
        st.error("M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán ho·∫∑c load!")
        return
        
    try:
        df = st.session_state.df_l3.copy()
        feature_cols = st.session_state.l3_feature_cols
        
        # L·∫•y 30 ng√†y cu·ªëi ƒë·ªÉ l√†m sequence ƒë·∫ßu v√†o
        last_30_days = df.dropna(subset=feature_cols).tail(30)
        scaled_sequence = st.session_state.l3_scaler.transform(last_30_days[feature_cols])
        
        # Predict
        pred_scaled = predict_lstm(st.session_state.l3_model, scaled_sequence)
        
        # Inverse transform
        pred_prices = st.session_state.l3_target_scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()
        
        # Dates
        last_date = df['Date'].max()
        pred_dates = [last_date + timedelta(days=i) for i in range(1, 8)]
        
        pred_df = pd.DataFrame({
            'Date': pred_dates,
            'Predicted_Price': pred_prices
        })
        
        st.session_state.l3_prediction = pred_df
        st.success("ƒê√£ ho√†n th√†nh d·ª± b√°o LSTM cho 7 ng√†y t·ªõi!")
        
    except Exception as e:
        st.error(f"L·ªói khi d·ª± b√°o LSTM: {e}")

def display_l3_prediction_results():
    """Hi·ªÉn th·ªã k·∫øt qu·∫£ d·ª± b√°o c·ªßa LSTM"""
    pred_df = st.session_state.l3_prediction
    
    # X√°c ƒë·ªãnh ngu·ªìn d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã l·ªãch s·ª≠
    if 'df_l3' in st.session_state:
        df_source = st.session_state.df_l3
    elif 'df_l3_raw' in st.session_state:
        df_source = st.session_state.df_l3_raw
    elif st.session_state.df_features is not None:
        df_source = st.session_state.df_features
    else:
        st.warning("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ ƒë·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì.")
        return

    df_hist = df_source.tail(20)
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("B·∫£ng d·ª± b√°o 7 ng√†y")
        fmt_df = pred_df.copy()
        fmt_df['Date'] = fmt_df['Date'].dt.strftime('%d/%m/%Y')
        fmt_df['Predicted_Price'] = fmt_df['Predicted_Price'].map('${:,.4f}'.format)
        st.table(fmt_df)
        
    with col2:
        st.subheader("Bi·ªÉu ƒë·ªì d·ª± b√°o Deep Learning")
        fig = go.Figure()
        
        # L·ªãch s·ª≠
        fig.add_trace(go.Scatter(
            x=df_hist['Date'], y=df_hist['Price'],
            mode='lines+markers', name='L·ªãch s·ª≠ (20 ng√†y)',
            line=dict(color='white')
        ))
        
        # D·ª± b√°o
        # N·ªëi ƒëi·ªÉm cu·ªëi l·ªãch s·ª≠ v·ªõi ƒëi·ªÉm ƒë·∫ßu d·ª± b√°o
        connect_date = [df_hist['Date'].iloc[-1]] + pred_df['Date'].tolist()
        connect_price = [df_hist['Price'].iloc[-1]] + pred_df['Predicted_Price'].tolist()
        
        fig.add_trace(go.Scatter(
            x=connect_date, y=connect_price,
            mode='lines+markers', name='LSTM Forecast',
            line=dict(color='#00D9FF', dash='dash', width=3)
        ))
        
        fig.update_layout(
            template='plotly_dark',
            margin=dict(l=10, r=10, t=30, b=10),
            height=450,
            xaxis_title="Ng√†y",
            yaxis_title="Gi√° XRP ($)",
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
        )
        
        st.plotly_chart(fig, use_container_width=True)


if __name__ == "__main__":
    main()
