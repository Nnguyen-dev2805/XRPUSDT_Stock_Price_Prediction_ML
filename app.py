import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import sys
from sklearn.metrics import mean_absolute_error
import plotly.graph_objects as go
import traceback

sys.path.append(os.path.dirname(__file__))

from utils import (
    load_data, get_latest_row, get_latest_n_rows,
    create_advanced_features, get_feature_columns, create_lstm_features,
    train_layer1_model, train_svr_model, train_layer2_model, load_model, save_model,
    predict_next_day_layer1, predict_layer2, create_prediction_with_confidence,
    evaluate_model, get_feature_importance, prepare_data_for_training,
    predict_multi_step_layer1, train_multi_horizon_models, 
    train_lstm_model, prepare_lstm_data, predict_lstm,
    plot_price_history, plot_candlestick, plot_volume,
    plot_technical_indicators, plot_prediction_result, plot_feature_importance,
    plot_prediction_30d,
    get_next_trading_date, format_number, calculate_change_percent,
    append_prediction_to_csv, validate_data
)

# Import new modules for Layer 3 enhancements
from utils.regime_lstm import (
    RegimeLSTM, create_regime_features, prepare_regime_data,
    train_regime_lstm, predict_regime_lstm
)
from utils.ml_ensemble import (
    MLEnsembleForecaster, train_ml_ensemble, create_ml_features
)

# Page config
st.set_page_config(
    page_title="H·ªá th·ªëng D·ª± b√°o Gi√° XRP ƒêa t·∫ßng",
    page_icon=None,
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    /* Global Font & Theme */
    html, body, [class*="css"] {
        font-family: 'Inter', system-ui, -apple-system, sans-serif;
        color: #31333F; /* Dark text for light background */
    }
    
    /* Header styling */
    .main-header {
        font-size: 1.8rem;
        font-weight: 700;
        color: #0E1117; /* Very dark blue-black */
        padding-bottom: 1rem;
        border-bottom: 2px solid #0E1117;
        margin-bottom: 1.5rem;
        text-transform: uppercase;
        letter-spacing: 1px;
    }
    
    /* Section Headers */
    .section-header {
        font-size: 1.1rem;
        font-weight: 700;
        color: #1F2937; /* Dark gray */
        margin-top: 1rem;
        margin-bottom: 0.5rem;
        text-transform: uppercase;
        border-left: 5px solid #FF4B4B; /* Red Accent */
        padding-left: 10px;
    }
    
    /* Custom Containers */
    div[data-testid="stVerticalBlock"] > div[style*="flex-direction: column;"] > div[data-testid="stVerticalBlock"] {
        background-color: #F8F9FA; /* Light gray background */
        border-radius: 8px;
        padding: 15px;
        border: 1px solid #E5E7EB;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    /* Global Secondary Buttons (Blue) */
    .stButton > button:not([kind="primary"]) {
        background-color: #007BFF !important;
        color: white !important;
        border: none !important;
        transition: background-color 0.2s;
    }
    .stButton > button:not([kind="primary"]):hover {
        background-color: #0062cc !important;
    }
    
    /* Primary buttons styling (Force Red) */
    .stButton > button[kind="primary"] {
        background-color: #FF4B4B !important;
        color: white !important;
        border: none !important;
    }
    .stButton > button[kind="primary"]:hover {
        background-color: #e63939 !important;
    }
    
    /* Buttons Styling */
    .stButton > button {
        border-radius: 4px;
        font-weight: 600;
        padding: 0.5rem 1rem;
    }

    /* Cards/Prediction Box */
    .prediction-box {
        background: #25262b;
        border: 1px solid #373a40;
        border-radius: 8px;
        padding: 1.5rem;
        text-align: center;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    
    /* Metric Cards */
    div[data-testid="metric-container"] {
        background-color: #25262b;
        border: 1px solid #373a40;
        padding: 10px 15px;
        border-radius: 6px;
    }
    
    /* Tabs styling - Modern & Clean */
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
        background-color: transparent;
        padding: 10px 0;
        border-bottom: 1px solid #E5E7EB;
    }
    
    .stTabs [data-baseweb="tab"] {
        height: 40px;
        border-radius: 0;
        color: #6B7280; /* Neutral Gray */
        font-weight: 500;
        background-color: transparent;
        border: none;
        padding: 0 4px;
    }
    
    .stTabs [data-baseweb="tab"]:hover {
        color: #FF4B4B;
        background-color: transparent;
    }
    
    .stTabs [aria-selected="true"] {
        background-color: transparent !important;
        color: #FF4B4B !important; /* Professional Red */
        font-weight: 700;
        border-bottom: 2px solid #FF4B4B !important;
    }
    
    hr {
        margin: 2rem 0;
        border-color: #E5E7EB;
    }
    
    /* Dashboard Market Card */
    .market-card-container {
        background-color: #ffffff;
        border: 1px solid #E5E7EB;
        border-radius: 12px;
        padding: 24px;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
    }
    
    .market-label {
        color: #6B7280;
        font-size: 0.875rem;
        font-weight: 500;
        text-transform: uppercase;
        letter-spacing: 0.05em;
        margin-bottom: 0.25rem;
    }
    
    .market-value-lg {
        color: #111827;
        font-size: 2.25rem;
        font-weight: 700;
        line-height: 2.5rem;
    }
    
    .market-value-sm {
        color: #1F2937;
        font-size: 1.25rem;
        font-weight: 600;
    }
    
    .trend-up { color: #059669; font-weight: 600; }
    .trend-down { color: #DC2626; font-weight: 600; }
    
    /* Input Form Styling */
    .input-form-box {
        background-color: #F9FAFB;
        border: 1px solid #E5E7EB;
        border-radius: 8px;
        padding: 20px;
    }

    /* Prediction Card Styling - Scientific/Professional Light Theme */
    .prediction-card {
        background-color: #FFFFFF;
        border: 1px solid #E5E7EB;
        border-radius: 12px;
        padding: 24px;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        text-align: center;
        transition: transform 0.2s;
    }
    .prediction-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1);
        border-color: #D1D5DB;
    }
    .pred-title {
        color: #374151;
        font-size: 1.1rem;
        font-weight: 600;
        margin-bottom: 0.5rem;
    }
    .pred-price {
        color: #111827;
        font-size: 2.5rem;
        font-weight: 800;
        margin: 1rem 0;
        font-variant-numeric: tabular-nums;
    }
    .pred-sub {
        color: #6B7280;
        font-size: 0.875rem;
        margin-bottom: 1rem;
    }
    .confidence-box {
        background-color: #F3F4F6;
        border-radius: 6px;
        padding: 8px;
        margin-top: 1rem;
        font-size: 0.875rem;
        color: #4B5563;
    }
</style>
""", unsafe_allow_html=True)

# Helper to get absolute path
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

DISPLAY_DATA_PATH = os.path.join(BASE_DIR, 'data', 'XRPUSDT_train.csv')
SOURCE_DATA_PATH = os.path.join(BASE_DIR, 'data', 'XRPUSDT20182024new.csv')

# Layer 1 paths
L1_MODEL_PATH = os.path.join(BASE_DIR, 'models', 'layer1_rf_model.pkl')
L1_SCALER_PATH = os.path.join(BASE_DIR, 'models', 'layer1_scaler.pkl')
L1_MULTI_MODELS_PATH = os.path.join(BASE_DIR, 'models', 'layer1_multi_models.pkl')
L1_MULTI_SCALERS_PATH = os.path.join(BASE_DIR, 'models', 'layer1_multi_scalers.pkl')
L1_SVR_MODEL_PATH = os.path.join(BASE_DIR, 'models', 'layer1_svr_model.pkl')
L1_SVR_SCALER_PATH = os.path.join(BASE_DIR, 'models', 'layer1_svr_scaler.pkl')
# Layer 2 paths (Single Ridge Stacking)
L2_RIDGE_MODEL_PATH = os.path.join(BASE_DIR, 'models', 'l2_ridge_model.pkl')
L2_RIDGE_SCALER_PATH = os.path.join(BASE_DIR, 'models', 'l2_ridge_scaler.pkl')
# Layer 3 paths
L3_MODEL_PATH = os.path.join(BASE_DIR, 'models', 'layer3_lstm_model.keras')
L3_SCALER_PATH = os.path.join(BASE_DIR, 'models', 'layer3_scaler.pkl')
L3_TARGET_SCALER_PATH = os.path.join(BASE_DIR, 'models', 'layer3_target_scaler.pkl')
ML_ENSEMBLE_MODEL_PATH = os.path.join(BASE_DIR, 'models', 'ml_ensemble_model.pkl')
REGIME_LSTM_MODEL_PATH = os.path.join(BASE_DIR, 'models', 'regime_lstm_model.pkl')
REGIME_LSTM_SCALERS_PATH = os.path.join(BASE_DIR, 'models', 'regime_lstm_scalers.pkl')

# Session state initialization
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False
if 'model' not in st.session_state:
    st.session_state.model = None
if 'scaler' not in st.session_state:
    st.session_state.scaler = None
if 'l1_multi_models' not in st.session_state:
    st.session_state.l1_multi_models = None
if 'l1_multi_scalers' not in st.session_state:
    st.session_state.l1_multi_scalers = None
if 'svr_model' not in st.session_state:
    st.session_state.svr_model = None
if 'svr_scaler' not in st.session_state:
    st.session_state.svr_scaler = None
if 'svr_model_trained' not in st.session_state:
    st.session_state.svr_model_trained = False
if 'df_features' not in st.session_state:
    st.session_state.df_features = None
if 'show_manual_input' not in st.session_state:
    st.session_state.show_manual_input = False
if 'active_data_path' not in st.session_state:
    st.session_state.active_data_path = DISPLAY_DATA_PATH
if 'metrics' not in st.session_state:
    st.session_state.metrics = None
if 'svr_metrics' not in st.session_state:
    st.session_state.svr_metrics = None
if 'feature_cols' not in st.session_state:
    st.session_state.feature_cols = None

# Layer 2 Session States (Single Ridge Stacking)
if 'l2_ridge_model_trained' not in st.session_state:
    st.session_state.l2_ridge_model_trained = False
if 'l2_ridge_model' not in st.session_state:
    st.session_state.l2_ridge_model = None
if 'l2_ridge_scaler' not in st.session_state:
    st.session_state.l2_ridge_scaler = None

# Layer 3 Session States
if 'l3_model_trained' not in st.session_state:
    st.session_state.l3_model_trained = False
if 'l3_model' not in st.session_state:
    st.session_state.l3_model = None
if 'l3_scaler' not in st.session_state:
    st.session_state.l3_scaler = None
if 'l3_target_scaler' not in st.session_state:
    st.session_state.l3_target_scaler = None

# Regime LSTM Session States (Layer 3 - Tab 2)
if 'regime_lstm_trained' not in st.session_state:
    st.session_state.regime_lstm_trained = False
if 'regime_lstm_model' not in st.session_state:
    st.session_state.regime_lstm_model = None
if 'regime_lstm_scalers' not in st.session_state:
    st.session_state.regime_lstm_scalers = None
if 'regime_lstm_metrics' not in st.session_state:
    st.session_state.regime_lstm_metrics = None

# ML Ensemble Session States (Layer 3 - Tab 3)
if 'ml_ensemble_trained' not in st.session_state:
    st.session_state.ml_ensemble_trained = False
if 'ml_ensemble_model' not in st.session_state:
    st.session_state.ml_ensemble_model = None
if 'ml_ensemble_metrics' not in st.session_state:
    st.session_state.ml_ensemble_metrics = None

def main():

    # Header
    st.markdown('<h1 class="main-header">H·ªÜ TH·ªêNG D·ª∞ ƒêO√ÅN GI√Å C·ªî PHI·∫æU XRP/USDT</h1>', unsafe_allow_html=True)
    
    # Sidebar
    # with st.sidebar:
    #     st.header("B·∫£ng ƒêi·ªÅu Khi·ªÉn")
    #     st.markdown("""
    #     **Ki·∫øn tr√∫c H·ªá th·ªëng:**
    #     1. **L·ªõp 1 (M√°y h·ªçc)**: X√°c ƒë·ªãnh Xu h∆∞·ªõng (RandomForest, SVR)
    #     2. **L·ªõp 2 (Th·ªëng k√™)**: Tinh ch·ªânh trong ng√†y (Ridge)
    #     3. **L·ªõp 3 (H·ªçc s√¢u)**: D·ª± b√°o chu·ªói th·ªùi gian (LSTM)
    #     """)
        

    # Tabs for different Layers
    tab1, tab2, tab3 = st.tabs(["D·ª± ƒëo√°n ng√†y ti·∫øp theo", "D·ª± ƒëo√°n trong ng√†y", "D·ª± ƒëo√°n d√†i h·∫°n"])
    
    with tab1:
        display_layer1_content()
    
    with tab2:
        display_layer2_content()
        
    with tab3:
        display_layer3_content()


def display_layer1_content():
    """Giao di·ªán ch√≠nh Layer 1 v·ªõi b·ªë c·ª•c l∆∞·ªõi t·ªëi ∆∞u"""
    
    # --- H√ÄNG 1: NH·∫¨P LI·ªÜU & HU·∫§N LUY·ªÜN ---
    col_top_left, col_top_right = st.columns([1, 1.8])
    
    with col_top_left:
        st.markdown('<div class="section-header">1. NH·∫¨P D·ªÆ LI·ªÜU</div>', unsafe_allow_html=True)
        with st.container(border=True):
            uploaded_file = st.file_uploader("CSV/Excel file", type=['csv', 'xlsx'], label_visibility="collapsed")
            
            col_btn1, col_btn2 = st.columns(2)
            with col_btn1:
                # N√∫t X·ª≠ l√Ω lu√¥n hi·ªán nh∆∞ng disabled n·∫øu ch∆∞a ch·ªçn file ƒë·ªÉ gi·ªØ layout
                if st.button("X·ª≠ l√Ω", use_container_width=True, type="primary", disabled=(uploaded_file is None)):
                    load_and_process_data(uploaded_file)
            with col_btn2:
                # N√∫t Xem Data (s·∫Ω t·ª± ƒë·ªông c√≥ m√†u xanh theo CSS secondary)
                if st.button("Xem Data", use_container_width=True, key="btn_view_data_l1"):
                    st.session_state.show_processed_data = not st.session_state.get('show_processed_data', False)

    with col_top_right:
        st.markdown('<div class="section-header">2. HU·∫§N LUY·ªÜN M√î H√åNH</div>', unsafe_allow_html=True)
        with st.container(border=True):
            # Tr·∫°ng th√°i m√¥ h√¨nh
            rf_status = "ƒê√£ train" if st.session_state.model_trained else "Ch∆∞a train"
            svr_status = "ƒê√£ train" if st.session_state.svr_model_trained else "Ch∆∞a train"
            st.caption(f"Tr·∫°ng th√°i: RF [{rf_status}] | SVR [{svr_status}]")
            
            # N√∫t hu·∫•n luy·ªán & Tinh ch·ªânh
            col_t1, col_t2 = st.columns(2)
            with col_t1:
                with st.expander("Tham s·ªë RF", expanded=False):
                    rf_n_estimators = st.number_input("n_estimators", 10, 2000, 500, 50, key="rf_n")
                    rf_max_depth = st.number_input("max_depth", 1, 50, 8, 1, key="rf_d")
                    rf_min_leaf = st.number_input("min_samples_leaf", 1, 100, 20, 1, key="rf_l")
                
                if st.button("Train RandomForest", use_container_width=True, type="primary"):
                    params = {
                        'n_estimators': rf_n_estimators,
                        'max_depth': rf_max_depth,
                        'min_samples_leaf': rf_min_leaf,
                        'random_state': 42,
                        'n_jobs': -1
                    }
                    train_model(model_type="RF", custom_params=params)
                    
            with col_t2:
                with st.expander("Tham s·ªë SVR", expanded=False):
                    svr_c = st.number_input("C (Regularization)", 0.01, 1000.0, 100.0, 10.0, key="svr_c")
                    svr_epsilon = st.number_input("Epsilon", 0.001, 1.0, 0.01, 0.005, format="%.3f", key="svr_e")
                    svr_kernel = st.selectbox("Kernel", ["rbf", "linear", "poly"], index=0, key="svr_k")
                
                if st.button("Train SVR (Vector)", use_container_width=True, type="primary"):
                    params = {
                        'C': svr_c,
                        'epsilon': svr_epsilon,
                        'kernel': svr_kernel,
                        'gamma': 'scale'
                    }
                    train_model(model_type="SVR", custom_params=params)
            
            st.divider()
            
            # Qu·∫£n l√Ω file m√¥ h√¨nh (D√πng Expander ƒë·ªÉ ti·∫øt ki·ªám di·ªán t√≠ch)
            with st.expander("T·∫£i m√¥ h√¨nh", expanded=False):
                m_tab1, m_tab2 = st.tabs(["T·∫£i M√¥ h√¨nh", "X√≥a M√¥ h√¨nh"])
                with m_tab1:
                    model_options = ["T·∫•t c·∫£ (All)", "RandomForest (1-Day)", "SVR (1-Day)", "D·ª± b√°o 7-Ng√†y"]
                    selected_load = st.selectbox("Ch·ªçn ƒë·ªÉ t·∫£i:", model_options, label_visibility="collapsed")
                    if st.button("T·∫£i M√¥ h√¨nh ƒê√£ ch·ªçn", use_container_width=True, type="primary"):
                        if selected_load == "T·∫•t c·∫£ (All)":
                            load_saved_model(model_type="ALL")
                            load_saved_7day_models()
                        elif selected_load == "RandomForest (1-Day)":
                            load_saved_model(model_type="RF")
                        elif selected_load == "SVR (1-Day)":
                            load_saved_model(model_type="SVR")
                        elif selected_load == "D·ª± b√°o 7-Ng√†y":
                            load_saved_7day_models()
                with m_tab2:
                    files_to_delete = st.multiselect(
                        "File c·∫ßn x√≥a:",
                        ["RandomForest", "SVR", "D·ª± b√°o 7-Ng√†y", "Layer 2 Models", "Layer 3 LSTM"],
                        default=[]
                    )
                    if st.button("X√≥a M√¥ h√¨nh ƒê√£ ch·ªçn", type="primary", use_container_width=True):
                        if files_to_delete:
                            delete_selected_models(files_to_delete)
                
            # Th√¥ng tin m√¥ h√¨nh hi·ªán t·∫°i (M·ªõi)
            if st.session_state.model_trained or st.session_state.svr_model_trained:
                with st.expander("Chi ti·∫øt m√¥ h√¨nh ƒëang t·∫£i", expanded=False):
                    if st.session_state.model_trained and st.session_state.model is not None:
                        st.markdown("**RandomForest (RF):**")
                        p = st.session_state.model.get_params()
                        st.json({k: p[k] for k in ['n_estimators', 'max_depth', 'min_samples_leaf'] if k in p})
                    
                    if st.session_state.svr_model_trained and st.session_state.svr_model is not None:
                        st.markdown("**SVR (Support Vector):**")
                        p = st.session_state.svr_model.get_params()
                        st.json({k: p[k] for k in ['C', 'epsilon', 'kernel', 'gamma'] if k in p})

    # Hi·ªÉn th·ªã b·∫£ng d·ªØ li·ªáu (Toggle) - Full width b√™n d∆∞·ªõi Row 1
    if st.session_state.get('show_processed_data', False):
        if st.session_state.df_features is not None:
            st.toast(f"ƒêang hi·ªÉn th·ªã {len(st.session_state.df_features)} d√≤ng ƒë√£ x·ª≠ l√Ω.")
            st.dataframe(st.session_state.df_features, use_container_width=True, height=300)
        else:
            st.warning("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc.")

    st.divider()

    # --- H√ÄNG 2: TH·ªä TR∆Ø·ªúNG & D·ª∞ B√ÅO & C·∫¨P NH·∫¨T ---
    if st.session_state.df_features is not None:
        # Load df_display ƒë·ªÉ d√πng cho c√°c component b√™n d∆∞·ªõi
        df_display = None
        if os.path.exists(DISPLAY_DATA_PATH):
            try: df_display = pd.read_csv(DISPLAY_DATA_PATH)
            except: pass

        col_main_left, col_main_right = st.columns([2.3, 1])
        
        with col_main_left:
            # 1. D·ªÆ LI·ªÜU TH·ªä TR∆Ø·ªúNG M·ªöI NH·∫§T (70% b·ªÅ ngang)
            display_market_status_card(st.session_state.df_features, df_display)
            
            # 1.5 K·∫æT QU·∫¢ D·ª∞ B√ÅO SO S√ÅNH (ƒê∆∞a v√†o kho·∫£ng tr·ªëng b√™n tr√°i)
            if 'prediction' in st.session_state:
                st.write("") # Spacer
                display_prediction_inline()
        
        with col_main_right:
            # 2. TH·ª∞C HI·ªÜN D·ª∞ ƒêO√ÅN (Ph·∫ßn tr√™n - 30% ngang)
            st.markdown('<div class="section-header">3. D·ª∞ ƒêO√ÅN</div>', unsafe_allow_html=True)
            # Hi·ªÉn th·ªã c√°c n√∫t x·∫øp ch·ªìng theo h√†ng d·ªçc
            with st.container(border=True):
                if st.button("D·ª∞ ƒêO√ÅN T+1", use_container_width=True, type="primary", 
                             disabled=not (st.session_state.model_trained or st.session_state.svr_model_trained)):
                    make_prediction()
                st.write("")
                if st.button("D·ª∞ ƒêO√ÅN T+7", use_container_width=True, 
                             disabled=not (st.session_state.model_trained or st.session_state.svr_model_trained)):
                    make_7day_prediction()
                st.caption("*Y√™u c·∫ßu m√¥ h√¨nh ƒë√£ s·∫µn s√†ng.")

            # 3. C·∫¨P NH·∫¨T D·ªÆ LI·ªÜU TH·ª∞C T·∫æ (Ph·∫ßn d∆∞·ªõi - 30% ngang)
            display_manual_input_form()

        # --- H√ÄNG 3: K·∫æT QU·∫¢ & PH√ÇN T√çCH ---
        st.divider()
        display_prediction_results_and_charts(st.session_state.df_features, df_display)
    else:
        # Khi ch∆∞a c√≥ d·ªØ li·ªáu
        col1, col2 = st.columns([2.3, 1])
        with col1:
            st.markdown('<div class="section-header">D·ªÆ LI·ªÜU TH·ªä TR∆Ø·ªúNG</div>', unsafe_allow_html=True)
            st.info("Vui l√≤ng b·∫Øt ƒë·∫ßu b·∫±ng vi·ªác **T·∫£i d·ªØ li·ªáu** ·ªü M·ª•c 1.")
        with col2:
            st.markdown('<div class="section-header">3. D·ª∞ ƒêO√ÅN</div>', unsafe_allow_html=True)
            st.warning("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc.")
        # st.info("")


#### load d·ªØ li·ªáu
def load_and_process_data(file_buffer=None, target_path=None):
    with st.spinner("ƒêang t·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu..."):
        try:
            # Load data
            if file_buffer is not None:
                df = pd.read_csv(file_buffer)
                df['Date'] = pd.to_datetime(df['Date'])
                df.drop(columns=['Change %'], errors='ignore', inplace=True)
                df = df.sort_values('Date').reset_index(drop=True)
            else:
                path = target_path if target_path else SOURCE_DATA_PATH
                df = load_data(path)
            
            # Validate
            is_valid, msg = validate_data(df)
            if not is_valid:
                st.error(f"D·ªØ li·ªáu kh√¥ng h·ª£p l·ªá: {msg}")
                return
            
            # Create features
            df_features = create_advanced_features(df)
            
            # # Sync RF & SVR predictions if they exist in the loaded file
            # if 'RF_Pred_Tomorrow' in df_features.columns:
            #     df_features['RF_Pred_Today'] = df_features['RF_Pred_Tomorrow'].shift(1)
            # if 'SVR_Pred_Tomorrow' in df_features.columns:
            #     df_features['SVR_Pred_Today'] = df_features['SVR_Pred_Tomorrow'].shift(1)
                
            # Store in session state
            st.session_state.df_features = df_features
            
            # Update active path
            if file_buffer is not None:
                # For uploaded files, save a local copy with its original name in the data folder
                save_filename = file_buffer.name
                save_path = os.path.join(BASE_DIR, 'data', save_filename)
                df.to_csv(save_path, index=False)
                st.session_state.active_data_path = save_path
            else:
                st.session_state.active_data_path = path
                
            st.toast(f"ƒê√£ t·∫£i {len(df)} d√≤ng d·ªØ li·ªáu th√†nh c√¥ng! (Ngu·ªìn: {st.session_state.active_data_path})")
            
        except Exception as e:
            st.error(f"L·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu: {e}")


#### train model
def train_model(model_type="RF", custom_params=None):
    if st.session_state.df_features is None:
        st.warning("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc!")
        return
    
    model_name = "RandomForest" if model_type == "RF" else "SVR"
    with st.spinner(f"ƒêang hu·∫•n luy·ªán m√¥ h√¨nh {model_name}..."):
        try:
            # Get feature columns
            # L·∫•y danh s√°ch feature chu·∫©n (95 c·ªôt)
            feature_cols = get_feature_columns()
            st.session_state.feature_cols = feature_cols
            
            # st.info(f"ƒêang chu·∫©n b·ªã d·ªØ li·ªáu v·ªõi {len(feature_cols)} features...")
            st.toast(f"ƒêang chu·∫©n b·ªã d·ªØ li·ªáu v·ªõi {len(feature_cols)} features...")
            
            # Prepare data
            X_train, X_test, y_train, y_test, _ = prepare_data_for_training(
                st.session_state.df_features,
                feature_columns=feature_cols,
                target_column='Target_Price',
                test_size=0.2
            )
            
            # L∆∞u danh s√°ch features v√†o session state ƒë·ªÉ d√πng khi d·ª± ƒëo√°n
            st.session_state.feature_cols = feature_cols
            
            if model_type == "RF":
                # Train RF
                model, scaler = train_layer1_model(X_train, y_train, params=custom_params)
                save_model(model, L1_MODEL_PATH)
                save_model(scaler, L1_SCALER_PATH)
                
                # Store in session state
                st.session_state.model = model
                st.session_state.scaler = scaler
                st.session_state.model_trained = True
                
                # Add predictions to dataframe
                # df_clean = st.session_state.df_features.dropna(subset=feature_cols + ['Target_Price'])
                # X_all_scaled = scaler.transform(df_clean[feature_cols])

                # predictions = model.predict(X_all_scaled)
                # st.session_state.df_features.loc[df_clean.index, 'RF_Pred_Tomorrow'] = predictions
                # st.session_state.df_features['RF_Pred_Today'] = st.session_state.df_features['RF_Pred_Tomorrow'].shift(1)
            else:
                # Train SVR
                model, scaler = train_svr_model(X_train, y_train, params=custom_params)
                save_model(model, L1_SVR_MODEL_PATH)
                save_model(scaler, L1_SVR_SCALER_PATH)
                
                # Store in session state
                st.session_state.svr_model = model
                st.session_state.svr_scaler = scaler
                st.session_state.svr_model_trained = True
                
                # Add predictions to dataframe
                # df_clean = st.session_state.df_features.dropna(subset=feature_cols + ['Target_Price'])
                # X_all_scaled = scaler.transform(df_clean[feature_cols])
                # predictions = model.predict(X_all_scaled)
                # st.session_state.df_features.loc[df_clean.index, 'SVR_Pred_Tomorrow'] = predictions
                # st.session_state.df_features['SVR_Pred_Today'] = st.session_state.df_features['SVR_Pred_Tomorrow'].shift(1)

            # Evaluate
            metrics = evaluate_model(model, scaler, X_test, y_test)
            # st.session_state.feature_cols = feature_cols
            
            # Display metrics
            # Display metrics
            # st.success(f"Hu·∫•n luy·ªán m√¥ h√¨nh {model_name} th√†nh c√¥ng!")
            st.toast(f"Hu·∫•n luy·ªán m√¥ h√¨nh {model_name} th√†nh c√¥ng!")
            
            # Store metrics specifically
            if model_type == "RF":
                st.session_state.metrics = metrics
            else:
                st.session_state.svr_metrics = metrics
                
        except Exception as e:
            st.error(f"L·ªói khi hu·∫•n luy·ªán m√¥ h√¨nh {model_name}: {e}")
            import traceback
            st.error(traceback.format_exc())


def load_saved_model(model_type="ALL"):
    """Load pre-trained models Layer 1 (RF & SVR) based on selection"""
    with st.spinner(f"ƒêang t·∫£i quy tr√¨nh m√¥ h√¨nh: {model_type}..."):
        try:
            # Feature columns are shared - l·∫•y 1 l·∫ßn ƒë·ªÉ d√πng chung
            if st.session_state.feature_cols is None:
                st.session_state.feature_cols = get_feature_columns()
            
            loaded_any = False
            
            # --- Load RF ---
            if model_type in ["ALL", "RF"]:
                try:
                    rf_model = load_model(L1_MODEL_PATH)
                    rf_scaler = load_model(L1_SCALER_PATH)
                    
                    if rf_model and rf_scaler:
                        # Check feature consistency
                        if hasattr(rf_scaler, 'n_features_in_') and rf_scaler.n_features_in_ != len(st.session_state.feature_cols):
                            st.error(f"‚ö†Ô∏è Scaler RF c≈© ({rf_scaler.n_features_in_} c·ªôt) kh√¥ng kh·ªõp v·ªõi {len(st.session_state.feature_cols)} c·ªôt hi·ªán t·∫°i. Vui l√≤ng train l·∫°i!")
                        else:
                            st.session_state.model = rf_model
                            st.session_state.scaler = rf_scaler
                            st.session_state.model_trained = True
                            loaded_any = True
                            st.toast("ƒê√£ t·∫£i Random Forest th√†nh c√¥ng!")
                except Exception as e:
                    st.warning(f"Kh√¥ng th·ªÉ t·∫£i RF: {e}")

            # --- Load SVR ---
            if model_type in ["ALL", "SVR"]:
                try:
                    svr_model = load_model(L1_SVR_MODEL_PATH)
                    svr_scaler = load_model(L1_SVR_SCALER_PATH)
                    
                    if svr_model and svr_scaler:
                        # Check feature consistency
                        if hasattr(svr_scaler, 'n_features_in_') and svr_scaler.n_features_in_ != len(st.session_state.feature_cols):
                            st.error(f"‚ö†Ô∏è Scaler SVR c≈© ({svr_scaler.n_features_in_} c·ªôt) kh√¥ng kh·ªõp v·ªõi {len(st.session_state.feature_cols)} c·ªôt hi·ªán t·∫°i. Vui l√≤ng train l·∫°i!")
                        else:
                            st.session_state.svr_model = svr_model
                            st.session_state.svr_scaler = svr_scaler
                            st.session_state.svr_model_trained = True
                            loaded_any = True
                            st.toast("ƒê√£ t·∫£i SVR th√†nh c√¥ng!")
                except Exception as e:
                    st.warning(f"Kh√¥ng th·ªÉ t·∫£i SVR: {e}")
            
            if not loaded_any:
                st.warning(f"Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh {model_type} h·ª£p l·ªá n√†o ƒë√£ l∆∞u.")
            
        except Exception as e:
            st.error(f"L·ªói chung khi t·∫£i m√¥ h√¨nh: {e}")


def load_saved_7day_models():
    """Load pre-trained 7-day models"""
    with st.spinner("ƒêang t·∫£i b·ªô m√¥ h√¨nh d·ª± b√°o 7 ng√†y..."):
        try:
            if st.session_state.feature_cols is None:
                st.session_state.feature_cols = get_feature_columns()

            multi_models = load_model(L1_MULTI_MODELS_PATH)
            multi_scalers = load_model(L1_MULTI_SCALERS_PATH)
            
            if multi_models and multi_scalers:
                st.session_state.l1_multi_models = multi_models
                st.session_state.l1_multi_scalers = multi_scalers
                st.toast("ƒê√£ t·∫£i th√†nh c√¥ng b·ªô m√¥ h√¨nh d·ª± b√°o 7 ng√†y!")
            else:
                st.warning("Kh√¥ng t√¨m th·∫•y file m√¥ h√¨nh 7 ng√†y ƒë√£ l∆∞u.")
        except Exception as e:
            st.error(f"L·ªói khi t·∫£i m√¥ h√¨nh 7 ng√†y: {e}")


def delete_selected_models(files_to_delete):
    """X√≥a c√°c m√¥ h√¨nh ƒë∆∞·ª£c ch·ªçn"""
    # Mapping t√™n hi·ªÉn th·ªã -> ƒë∆∞·ªùng d·∫´n file
    mapping = {
        "RandomForest": [L1_MODEL_PATH, L1_SCALER_PATH],
        "SVR": [L1_SVR_MODEL_PATH, L1_SVR_SCALER_PATH],
        "D·ª± b√°o 7-Ng√†y": [L1_MULTI_MODELS_PATH, L1_MULTI_SCALERS_PATH],
        "Layer 2 Models": ["models/layer2_ridge_model.pkl", "models/layer2_ridge_scaler.pkl", "models/layer2_svr_model.pkl", "models/layer2_svr_scaler.pkl"],
        "Layer 3 LSTM": ["models/layer3_lstm_model.keras", "models/layer3_scaler.pkl", "models/layer3_target_scaler.pkl"]
    }
    
    deleted_count = 0
    for key in files_to_delete:
        paths = mapping.get(key, [])
        for p in paths:
            if os.path.exists(p):
                try:
                    os.remove(p)
                    deleted_count += 1
                except Exception as e:
                    st.error(f"Kh√¥ng x√≥a ƒë∆∞·ª£c {p}: {e}")
    
    if deleted_count > 0:
        st.toast(f"ƒê√£ x√≥a {deleted_count} file m√¥ h√¨nh th√†nh c√¥ng!", icon="üóëÔ∏è")
        
        # C·∫≠p nh·∫≠t l·∫°i session state sau khi x√≥a
        if "RandomForest" in files_to_delete:
            st.session_state.model = None
            st.session_state.model_trained = False
        if "SVR" in files_to_delete:
            st.session_state.svr_model = None
            st.session_state.svr_model_trained = False
            
        time.sleep(1) # Delay nh·∫π ƒë·ªÉ hi·ªÉn th·ªã toast
        st.rerun()
    else:
        st.warning("Kh√¥ng t√¨m th·∫•y file n√†o ƒë·ªÉ x√≥a (c√≥ th·ªÉ ƒë√£ b·ªã x√≥a tr∆∞·ªõc ƒë√≥).")

                



# Nh·∫•n d·ª± ƒëo√°n 1 ng√†y
def make_prediction():
    if st.session_state.df_features is None:
        st.warning("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc!")
        return
        
    if not st.session_state.model_trained and not st.session_state.svr_model_trained:
        st.warning("Ch∆∞a c√≥ m√¥ h√¨nh n√†o ƒë∆∞·ª£c hu·∫•n luy·ªán!")
        return
    
    with st.spinner("ƒêang t√≠nh to√°n d·ª± ƒëo√°n..."):
        try:
            df = st.session_state.df_features
            # Xu·∫•t d·ªØ li·ªáu ra file CSV ƒë·ªÉ ki·ªÉm tra
            df.to_csv('debug_df_features.csv', index=False)
            print(f"ƒê√£ xu·∫•t d·ªØ li·ªáu df_features ra file: debug_df_features.csv")
            
            latest_row = df.iloc[-1]
            print("\n" + "="*60)
            print("DEBUG: CHI TI·∫æT D√íNG D·ªÆ LI·ªÜU CU·ªêI C√ôNG (LATEST ROW)")
            print("-" * 64)
            print(latest_row.to_string())
            print("-" * 64)
            print("="*60 + "\n")
            
            # Prepare feature data (handle NaNs) - CH·ªà L·∫§Y C√ÅC C·ªòT FEATURES (Lo·∫°i b·ªè Date)
            # L·∫•y d√≤ng cu·ªëi c√πng c·ªßa df (d√≤ng m·ªõi nh·∫•t ng∆∞·ªùi d√πng v·ª´a nh·∫≠p ho·∫∑c t·∫£i l√™n)
            feature_cols = st.session_state.feature_cols
            df_cleaned = df[feature_cols].copy().ffill().fillna(0)
            
            latest_features = df_cleaned.iloc[-1:].values
            pred_date = get_next_trading_date(latest_row['Date'])
            
            comparison_results = {}
            
            # Predict with RF if available
            if st.session_state.model_trained:
                pred_rf = create_prediction_with_confidence(
                    st.session_state.model, 
                    st.session_state.scaler,
                    latest_features
                )
                comparison_results['RF'] = {
                    'price': pred_rf['prediction'],
                    'lower': pred_rf['lower_bound'],
                    'upper': pred_rf['upper_bound']
                }
                
            # Predict with SVR if available
            # Predict with SVR if available
            if st.session_state.svr_model_trained:
                try:
                    # Ki·ªÉm tra s·ªë features tr∆∞·ªõc khi transform
                    if hasattr(st.session_state.svr_scaler, 'n_features_in_'):
                        expected = st.session_state.svr_scaler.n_features_in_
                        actual = latest_features.shape[1]
                        if expected != actual:
                            raise ValueError(f"SVR Model c≈© mong ƒë·ª£i {expected} features nh∆∞ng code m·ªõi cung c·∫•p {actual}. C·∫ßn Train l·∫°i SVR!")

                    svr_pred_scaled = st.session_state.svr_model.predict(
                        st.session_state.svr_scaler.transform(latest_features)
                    )[0]
                    comparison_results['SVR'] = {
                        'price': svr_pred_scaled,
                        'lower': svr_pred_scaled * 0.98, # Theoretical interval
                        'upper': svr_pred_scaled * 1.02
                    }
                except Exception as e:
                    st.error(f"L·ªói SVR: {e}")
                    st.warning("M√¥ h√¨nh SVR hi·ªán t·∫°i kh√¥ng t∆∞∆°ng th√≠ch v·ªõi d·ªØ li·ªáu m·ªõi. H·ªá th·ªëng s·∫Ω b·ªè qua SVR trong l·∫ßn n√†y. Vui l√≤ng nh·∫•n n√∫t 'Train SVR' ƒë·ªÉ hu·∫•n luy·ªán l·∫°i!")
                    # T·∫°m th·ªùi v√¥ hi·ªáu h√≥a SVR ƒë·ªÉ kh√¥ng g√¢y l·ªói ti·∫øp
                    # st.session_state.svr_model_trained = False 
            
            st.session_state.prediction = {
                'date': pred_date,
                'current_price': latest_row['Price'],
                'results': comparison_results
            }
            
            # Th√™m c√°c ph√≠m ph·∫≥ng cho t√≠nh t∆∞∆°ng th√≠ch v·ªõi h√†m l∆∞u CSV (m·∫∑c ƒë·ªãnh l·∫•y RF)
            if 'RF' in comparison_results:
                st.session_state.prediction.update({
                    'predicted_price': comparison_results['RF']['price'],
                    'upper_bound': comparison_results['RF']['upper'],
                    'lower_bound': comparison_results['RF']['lower']
                })
            elif 'SVR' in comparison_results:
                st.session_state.prediction.update({
                    'predicted_price': comparison_results['SVR']['price'],
                    'upper_bound': comparison_results['SVR']['upper'],
                    'lower_bound': comparison_results['SVR']['lower']
                })
            
            st.toast("ƒê√£ c·∫≠p nh·∫≠t d·ª± ƒëo√°n so s√°nh!")
            st.rerun() # Bu·ªôc Streamlit ch·∫°y l·∫°i ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£ ngay l·∫≠p t·ª©c
            
        except Exception as e:
            st.error(f"L·ªói khi d·ª± ƒëo√°n: {e}")


def make_7day_prediction():
    """Make 7-day prediction using multi-horizon models (train on demand if needed)"""
    if st.session_state.df_features is None:
        st.warning("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc!")
        return

    # Check if multi-horizon models are already trained/loaded
    if st.session_state.l1_multi_models is None:
        with st.status("ƒêang hu·∫•n luy·ªán b·ªô 7 m√¥ h√¨nh chuy√™n bi·ªát cho d·ª± b√°o 7 ng√†y...", expanded=True) as status:
            try:
                st.write("D·ªØ li·ªáu ƒëang ƒë∆∞·ª£c chu·∫©n b·ªã...")
                feature_cols = get_feature_columns()
                
                st.write("B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán (quy tr√¨nh n√†y c√≥ th·ªÉ m·∫•t 1-2 ph√∫t)...")
                horizon_results = train_multi_horizon_models(st.session_state.df_features, feature_cols, days=7)
                
                multi_models = horizon_results['models']
                multi_scalers = horizon_results['scalers']
                
                # Save models
                save_model(multi_models, L1_MULTI_MODELS_PATH)
                save_model(multi_scalers, L1_MULTI_SCALERS_PATH)
                
                # Update session state
                st.session_state.l1_multi_models = multi_models
                st.session_state.l1_multi_scalers = multi_scalers
                st.session_state.feature_cols = feature_cols
                
                status.update(label="ƒê√£ hu·∫•n luy·ªán xong b·ªô 7 m√¥ h√¨nh!", state="complete", expanded=False)
            except Exception as e:
                status.update(label=f"L·ªói khi hu·∫•n luy·ªán: {e}", state="error")
                return

    with st.spinner("ƒêang t√≠nh to√°n d·ª± ƒëo√°n cho 7 ng√†y t·ªõi..."):
        try:
            # Prepare df for history
            df = st.session_state.df_features
            
            # Predict using the 7 individual models
            forecast_df = predict_multi_step_layer1(
                st.session_state.l1_multi_models,
                st.session_state.l1_multi_scalers,
                df,
                st.session_state.feature_cols,
                create_advanced_features,
                days=7
            )
            
            # Store in session state
            st.session_state.prediction_7days = forecast_df
            st.toast("ƒê√£ ho√†n th√†nh d·ª± ƒëo√°n xu h∆∞·ªõng 7 ng√†y!", icon="üìà")
            st.rerun() # Bu·ªôc Streamlit ch·∫°y l·∫°i ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£ ngay l·∫≠p t·ª©c
            
        except Exception as e:
            st.error(f"L·ªói khi d·ª± ƒëo√°n 7 ng√†y: {e}")
            import traceback
            st.error(traceback.format_exc())


def update_csv_with_prediction(prediction_val, col_name='RF_Pred_Tomorrow', target_path=None):
    """Update the latest row in CSV with the prediction value"""
    if target_path is None:
        target_path = st.session_state.get('active_data_path', DISPLAY_DATA_PATH)
    try:
        df_csv = pd.read_csv(target_path)
        # N·∫øu c·ªôt ch∆∞a c√≥ th√¨ t·∫°o m·ªõi
        if col_name not in df_csv.columns:
            df_csv[col_name] = pd.NA
            
        # Assuming Date is unique and sorted -> update last row
        # X√°c ƒë·ªãnh v·ªã tr√≠ c·ªôt c·∫©n th·∫≠n
        col_idx = df_csv.columns.get_loc(col_name)
        df_csv.iloc[-1, col_idx] = prediction_val
        
        df_csv.to_csv(target_path, index=False)
        return True
    except Exception as e:
        st.error(f"L·ªói khi c·∫≠p nh·∫≠t CSV: {e}")
        return False


def display_market_status_card(df, df_display):
    """Hi·ªÉn th·ªã th·∫ª tr·∫°ng th√°i th·ªã tr∆∞·ªùng (Ch·ªâ ph·∫ßn Card OHLV)"""
    # Latest data section - Only show latest date and single row
    st.markdown('<div class="section-header">D·ªÆ LI·ªÜU TH·ªä TR∆Ø·ªúNG M·ªöI NH·∫§T</div>', unsafe_allow_html=True)
    
    latest = get_latest_row(df)
    
    # --- Custom Market Dashboard Card ---
    with st.container():
        # T√≠nh to√°n change percent
        change_val = latest.get('Return_1d', 0)
        trend_class = "trend-up" if change_val >= 0 else "trend-down"
        trend_arrow = "‚ñ≤" if change_val >= 0 else "‚ñº"
        
        # HTML Custom Layout
        col_main, col_details = st.columns([1.5, 3])
        
        with col_main:
            st.markdown(f"""
<div style="padding: 10px;">
<div class="market-label">Ng√†y giao d·ªãch</div>
<div style="font-size: 1.1rem; font-weight: 500; color: #374151; margin-bottom: 15px;">{latest['Date'].strftime('%d/%m/%Y')}</div>
<div class="market-label">Gi√° ƒê√≥ng C·ª≠a (Close)</div>
<div class="market-value-lg">${format_number(latest['Price'])}</div>
<div class="{trend_class}" style="margin-top: 5px; font-size: 1rem;">
{trend_arrow} {format_number(abs(change_val), 2)}%
</div>
</div>
""", unsafe_allow_html=True)
            
        with col_details:
            # D√πng HTML Grid thay v√¨ st.columns ƒë·ªÉ tr√°nh l·ªói l·ªìng c·ªôt (Nested Columns)
            data_points = [
                ("M·ªü c·ª≠a (Open)", f"${format_number(latest['Open'])}"),
                ("Cao nh·∫•t (High)", f"${format_number(latest['High'])}"),
                ("Th·∫•p nh·∫•t (Low)", f"${format_number(latest['Low'])}"),
                ("Volume", f"{int(latest['Vol']):,}")
            ]
            
            grid_html = '<div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 10px;">'
            for label, fmt_val in data_points:
                grid_html += f'<div style="background: #F3F4F6; padding: 10px; border-radius: 8px; text-align: center;">'
                grid_html += f'<div class="market-label" style="font-size: 0.7rem;">{label}</div>'
                grid_html += f'<div class="market-value-sm" style="font-size: 0.9rem;">{fmt_val}</div>'
                grid_html += '</div>'
            grid_html += '</div>'
            
            st.markdown(grid_html, unsafe_allow_html=True)
            st.caption("C·∫≠p nh·∫≠t t·ª´ file ngu·ªìn.")

    # Show only the latest row in a clean table
    with st.expander("Xem chi ti·∫øt d√≤ng d·ªØ li·ªáu th√¥ (D√≤ng cu·ªëi c√πng)", expanded=False):
        # Determine which columns to show as requested by user
        base_cols = ['Date', 'Price', 'Open', 'High', 'Low', 'Vol']
        latest_row_df = df[base_cols].tail(1).copy()
    
        # Add prediction columns from DISPLAY_DATA_PATH if available
        if df_display is not None and not df_display.empty:
            last_display = df_display.iloc[-1]
            for c in ['RF_Pred_Tomorrow', 'RF_Pred_Today', 'SVR_Pred_Tomorrow', 'SVR_Pred_Today']:
                if c in df_display.columns:
                    latest_row_df[c] = last_display[c]
    
        latest_row_df['Date'] = latest_row_df['Date'].dt.strftime('%d/%m/%Y')
        for col in latest_row_df.columns:
            if col != 'Date' and col != 'Vol':
                latest_row_df[col] = latest_row_df[col].apply(lambda x: f"${x:.4f}" if pd.notna(x) else "N/A")
            elif col == 'Vol':
                latest_row_df[col] = latest_row_df[col].apply(lambda x: f"{int(x):,}" if pd.notna(x) else "N/A")
        
        st.dataframe(latest_row_df, use_container_width=True, hide_index=True)


def display_prediction_results_and_charts(df, df_display):
    """Hi·ªÉn th·ªã k·∫øt qu·∫£ d·ª± b√°o 7 ng√†y v√† bi·ªÉu ƒë·ªì ph√¢n t√≠ch (Ph·∫ßn d∆∞·ªõi c√πng)"""
    # 1-day prediction results have been moved to the Dashboard area
    
    # Display 7-day prediction if available
    if 'prediction_7days' in st.session_state:
        display_7day_prediction_inline()
        st.markdown("---")
    
    # Charts section
    st.header("Ph√¢n t√≠ch gi√°")
    tab1, tab2, tab3, tab4 = st.tabs(["L·ªãch s·ª≠ Gi√°", "Bi·ªÉu ƒë·ªì N·∫øn", "Kh·ªëi l∆∞·ª£ng", "Ch·ªâ b√°o K·ªπ thu·∫≠t"])
    
    with tab1:
        st.plotly_chart(plot_price_history(df, n_days=100), use_container_width=True)
    with tab2:
        st.plotly_chart(plot_candlestick(df, n_days=60), use_container_width=True)
    with tab3:
        st.plotly_chart(plot_volume(df, n_days=60), use_container_width=True)
    with tab4:
        st.plotly_chart(plot_technical_indicators(df, n_days=60), use_container_width=True)
    

def display_prediction_inline():
    """Display prediction results inline with comparison"""
    if 'prediction' not in st.session_state:
        return
    
    pred = st.session_state.prediction
    results = pred['results']
    
    st.markdown('<div class="section-header">K·∫æT QU·∫¢ D·ª∞ ƒêO√ÅN</div>', unsafe_allow_html=True)
    
    # Display cards for each model
    cols = st.columns(len(results))
    
    for i, (m_type, data) in enumerate(results.items()):
        with cols[i]:
            title = "RandomForest" if m_type == "RF" else "SVR (Support Vector Regression)"
            
            change = data['price'] - pred['current_price']
            change_pct = (change / pred['current_price']) * 100
            
            # Professional Financial Colors
            color = "#00b894" if change >= 0 else "#ff7675" # Green/Red flat colors
            arrow = "‚ñ≤" if change >= 0 else "‚ñº"

            st.markdown(f"""
<div class="prediction-card">
<div class="pred-title">{title}</div>
<div class="pred-sub">M·ª•c ti√™u: {pred['date'].strftime('%d/%m/%Y')}</div>
<div class="pred-price">${format_number(data['price'])}</div>
<div style="margin-bottom: 1rem;">
<span style="color: {color}; font-weight: 700; font-size: 1.2rem; background: {color}15; padding: 4px 12px; border-radius: 20px;">
{arrow} {format_number(abs(change_pct), 2)}%
</span>
</div>
<div class="confidence-box">
<span style="display: block; font-size: 0.75rem; text-transform: uppercase; color: #6B7280; margin-bottom: 4px;">Kho·∫£ng tin c·∫≠y (95%)</span>
<span style="font-weight: 600; color: #374151;">${format_number(data['lower'])} - ${format_number(data['upper'])}</span>
</div>
</div>
""", unsafe_allow_html=True)

    st.markdown("<br>", unsafe_allow_html=True)
    
    # --- New Chart: 30d History + Prediction ---
    if st.session_state.df_features is not None:
        fig_context = plot_prediction_30d(
            st.session_state.df_features, 
            results, 
            pred['date']
        )
        st.plotly_chart(fig_context, use_container_width=True)
    
    st.markdown("<br>", unsafe_allow_html=True)
    col1, col2 = st.columns(2)
    
    # Save action for RF
    with col1:
        if 'RF' in results:
            if st.button("L∆∞u d·ª± ƒëo√°n RF v√†o CSV", use_container_width=True, type="primary"):
                save_prediction_to_csv(model_type='RF')

    # Save action for SVR
    with col2:
        if 'SVR' in results:
            if st.button("L∆∞u d·ª± ƒëo√°n SVR v√†o CSV", use_container_width=True, type="primary"):
                save_prediction_to_csv(model_type='SVR')


def display_7day_prediction_inline():
    """Display 7-day forecast results with table and chart"""
    st.header("D·ª± ƒëo√°n gi√° 7 ng√†y")
    
    forecast_df = st.session_state.prediction_7days
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("B·∫£ng d·ª± ƒëo√°n")
        display_df = forecast_df.copy()
        display_df['Date'] = display_df['Date'].dt.strftime('%d/%m/%Y')
        display_df['Predicted_Price'] = display_df['Predicted_Price'].apply(lambda x: f"${x:.4f}")
        st.dataframe(display_df, use_container_width=True, hide_index=True)
    
    with col2:
        st.subheader("Bi·ªÉu ƒë·ªì Xu h∆∞·ªõng")
        
        # Th√™m gi√° hi·ªán t·∫°i v√†o bi·ªÉu ƒë·ªì ƒë·ªÉ th·∫•y s·ª± k·∫øt n·ªëi
        df_hist = st.session_state.df_features.tail(5)
        
        fig = go.Figure()
        
        # ƒê∆∞·ªùng gi√° l·ªãch s·ª≠ ng·∫Øn
        fig.add_trace(go.Scatter(
            x=df_hist['Date'], y=df_hist['Price'],
            mode='lines+markers', name='Th·ª±c t·∫ø',
            line=dict(color='blue')
        ))
        
        # ƒê∆∞·ªùng d·ª± ƒëo√°n
        # K·∫øt n·ªëi ƒëi·ªÉm cu·ªëi th·ª±c t·∫ø v·ªõi ƒëi·ªÉm ƒë·∫ßu d·ª± ƒëo√°n
        x_pred = [df_hist['Date'].iloc[-1]] + forecast_df['Date'].tolist()
        y_pred = [df_hist['Price'].iloc[-1]] + forecast_df['Predicted_Price'].tolist()
        
        fig.add_trace(go.Scatter(
            x=x_pred, y=y_pred,
            mode='lines+markers', name='D·ª± ƒëo√°n (7 ng√†y)',
            line=dict(color='orange', dash='dash')
        ))
        
        fig.update_layout(
            template='plotly_white',
            margin=dict(l=20, r=20, t=20, b=20),
            height=400,
            xaxis_title="Ng√†y",
            yaxis_title="Gi√° XRP ($)"
        )
        
        st.plotly_chart(fig, use_container_width=True)


def save_prediction_to_csv(model_type='RF'):
    """Save prediction to CSV file"""
    target_path = st.session_state.get('active_data_path', DISPLAY_DATA_PATH)
    
    if 'prediction' not in st.session_state:
        st.warning("Kh√¥ng c√≥ d·ª± ƒëo√°n ƒë·ªÉ l∆∞u!")
        return
    
    pred = st.session_state.prediction
    results = pred['results']
    
    # X√°c ƒë·ªãnh gi√° tr·ªã v√† t√™n c·ªôt c·∫ßn l∆∞u d·ª±a tr√™n model_type
    if model_type == 'RF':
        if 'RF' not in results: return
        pred_price = results['RF']['price']
        target_col = 'RF_Pred_Tomorrow'
    else:  # SVR
        if 'SVR' not in results: return
        pred_price = results['SVR']['price']
        target_col = 'SVR_Pred_Tomorrow'

    is_new_prediction = pred.get('is_new_prediction', True)
    
    if is_new_prediction:
        # Check if we should update an existing row (where RF_Pred_Tomorrow was NaN)
        # or append a completely new row.
        # If the prediction date matches the "tomorrow" of the last row in df
        df = st.session_state.df_features
        latest_date = df.iloc[-1]['Date']
        
        # If the prediction is indeed for the 'tomorrow' of the last existing row
        # we update that row's RF_Pred_Tomorrow column
        success = update_csv_with_prediction(pred_price, col_name=target_col, target_path=target_path)
        
        if success:
            st.success(f"ƒê√£ c·∫≠p nh·∫≠t d·ª± ƒëo√°n {model_type} cho ng√†y {pred['date'].strftime('%d/%m/%Y')} v√†o d·ªØ li·ªáu hi·ªán c√≥!")
            load_and_process_data(target_path=target_path) # Reload t·ª´ file v·ª´a l∆∞u
            st.rerun() # L√†m m·ªõi giao di·ªán ngay l·∫≠p t·ª©c
        else:
            # Fallback to append if update fails or logic dictates
            # Note: Ch·ªâ append d√≤ng m·ªõi n·∫øu l√† RF (ch√≠nh), SVR ch·ªâ update
            if model_type == 'RF':
                prediction_data = {
                    'Date': pred['date'],
                    'Price': pred_price,
                    'Open': pred_price,
                    'High': results['RF']['upper'],
                    'Low': results['RF']['lower'],
                    'Vol': 0
                }
                if append_prediction_to_csv(target_path, prediction_data):
                    st.success("ƒê√£ th√™m d√≤ng d·ª± ƒëo√°n m·ªõi v√†o CSV!")
                load_and_process_data(target_path=target_path)
                st.rerun()
            else:
                st.error("L∆∞u d·ª± ƒëo√°n th·∫•t b·∫°i")
    else:
        st.info("D·ª± ƒëo√°n n√†y ƒë√£ t·ªìn t·∫°i trong t·ªáp d·ªØ li·ªáu.")



def display_manual_input_form():
    """Hi·ªÉn th·ªã form nh·∫≠p d·ªØ li·ªáu th·ª±c t·∫ø cho ng√†y ti·∫øp theo"""
    df = st.session_state.df_features
    latest_date = df.iloc[-1]['Date']
    next_date = get_next_trading_date(latest_date)
    
    target_path = st.session_state.get('active_data_path', DISPLAY_DATA_PATH)
    target_filename = os.path.basename(target_path)
    
    st.markdown(f'<div class="section-header">C·∫¨P NH·∫¨T D·ªÆ LI·ªÜU TH·ª∞C T·∫æ: {next_date.strftime("%d/%m/%Y")}</div>', unsafe_allow_html=True)
    
    with st.container(border=True):
        st.caption(f"üìÅ T·ªáp ƒëang c·∫≠p nh·∫≠t: **{target_filename}**")
        st.write("Vui l√≤ng nh·∫≠p th√¥ng tin th·ªã tr∆∞·ªùng ch·ªët phi√™n ƒë·ªÉ c·∫≠p nh·∫≠t h·ªá th·ªëng:")
        
        with st.form("manual_input_form", clear_on_submit=True):
            price = st.number_input("Gi√° ƒê√≥ng (Close)", value=None, format="%.4f", placeholder="0.0000")
            vol = st.number_input("Kh·ªëi l∆∞·ª£ng (Volume)", value=None, step=1000, placeholder="Nh·∫≠p volume...")
            
            c_ohl1, c_ohl2 = st.columns(2)
            with c_ohl1:
                open_p = st.number_input("M·ªü (Open)", value=None, format="%.4f", placeholder="0.0000")
                high = st.number_input("Cao (High)", value=None, format="%.4f", placeholder="0.0000")
            with c_ohl2:
                low = st.number_input("Th·∫•p (Low)", value=None, format="%.4f", placeholder="0.0000")
            
            st.markdown("<br>", unsafe_allow_html=True)
            submit = st.form_submit_button("X√ÅC NH·∫¨N C·∫¨P NH·∫¨T", use_container_width=True, type="primary")
            if submit:
                if any(v is None for v in [price, vol, open_p, high, low]):
                    st.error("Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß t·∫•t c·∫£ c√°c tr∆∞·ªùng d·ªØ li·ªáu!")
                else:
                    handle_manual_input_submission(next_date, price, open_p, high, low, vol)
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£ v·ª´a d·ª± ƒëo√°n n·∫øu c√≥
    if 'last_manual_result' in st.session_state:
        st.success("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t th√†nh c√¥ng!")
        st.markdown("#### K·∫øt qu·∫£ d·ª± ƒëo√°n cho d√≤ng d·ªØ li·ªáu v·ª´a nh·∫≠p:")
        st.dataframe(st.session_state.last_manual_result, use_container_width=True, hide_index=True)


def handle_manual_input_submission(date, price, open_p, high, low, vol):
    """X·ª≠ l√Ω l∆∞u d·ªØ li·ªáu th·ª±c t·∫ø v√† T·∫§T C·∫¢ c√°c ch·ªâ s·ªë k·ªπ thu·∫≠t v√†o CSV"""
    target_path = st.session_state.get('active_data_path', DISPLAY_DATA_PATH)
    try:
        # 1. Load d·ªØ li·ªáu hi·ªán t·∫°i ch·ªâ l·∫•y c√°c c·ªôt g·ªëc ƒë·ªÉ tr√°nh b·ªã l·∫∑p c·ªôt features c≈©
        df_raw = load_data(target_path)
        base_cols = ['Date', 'Price', 'Open', 'High', 'Low', 'Vol']
        df_base = df_raw[base_cols].copy()
        
        # 2. Th√™m d√≤ng m·ªõi v√†o base data
        new_row = pd.DataFrame([{
            'Date': date,
            'Price': price,
            'Open': open_p,
            'High': high,
            'Low': low,
            'Vol': vol
        }])
        df_base = pd.concat([df_base, new_row], ignore_index=True)
        
        # 3. T√≠nh to√°n l·∫°i TO√ÄN B·ªò features tr√™n d·ªØ li·ªáu ƒë√£ n·ªëi
        df_all_features = create_advanced_features(df_base)
        
        # ƒê·∫£m b·∫£o RF_Pred_Today ƒë∆∞·ª£c t√≠nh t·ª´ RF_Pred_Tomorrow c·ªßa ng√†y tr∆∞·ªõc ƒë√≥ (n·∫øu c√≥)
        if 'RF_Pred_Tomorrow' in df_raw.columns:
            # Copy c·ªôt d·ª± b√°o c≈© sang ƒë·ªÉ kh√¥ng b·ªã m·∫•t d·ªØ li·ªáu l·ªãch s·ª≠
            df_all_features['RF_Pred_Tomorrow'] = df_raw['RF_Pred_Tomorrow']
            df_all_features.loc[df_all_features.index[-1], 'RF_Pred_Tomorrow'] = np.nan
        
        # 4. Th·ª±c hi·ªán d·ª± b√°o RF_Pred_Tomorrow cho d√≤ng v·ª´a th√™m
        if st.session_state.model is not None and st.session_state.scaler is not None:
            feature_cols = get_feature_columns()
            # X·ª≠ l√Ω NaN v√† Infinity cho features tr∆∞·ªõc khi d·ª± b√°o
            df_for_pred = df_all_features[feature_cols].copy().replace([np.inf, -np.inf], np.nan).ffill().fillna(0)
            latest_features = df_for_pred.iloc[-1:].values
            
            # D·ª± b√°o gi√° cho ng√†y ti·∫øp theo
            pred_val = predict_next_day_layer1(st.session_state.model, st.session_state.scaler, latest_features)
            df_all_features.loc[df_all_features.index[-1], 'RF_Pred_Tomorrow'] = pred_val
            
        # 5. C·∫≠p nh·∫≠t RF_Pred_Today (L·∫•y d·ª± b√°o c·ªßa ng√†y tr∆∞·ªõc ƒë√≥ g√°n cho h√¥m nay)
        if 'RF_Pred_Tomorrow' in df_all_features.columns:
            df_all_features['RF_Pred_Today'] = df_all_features['RF_Pred_Tomorrow'].shift(1)
            
        # 6. L∆∞u d·ªØ li·ªáu th√¥ (Ch·ªâ Input v√† Date) v√†o CSV
        # User y√™u c·∫ßu ch·ªâ l∆∞u input v√† date v√†o file ƒë√£ ch·ªçn
        base_cols = ['Date', 'Price', 'Open', 'High', 'Low', 'Vol']
        # ƒê·∫£m b·∫£o c√°c c·ªôt t·ªìn t·∫°i trong df_all_features
        cols_to_save = [c for c in base_cols if c in df_all_features.columns]
        df_save = df_all_features[cols_to_save].copy()
        df_save['Date'] = df_save['Date'].dt.strftime('%Y-%m-%d')
        df_save.to_csv(target_path, index=False)
        
        # 7. C·∫≠p nh·∫≠t giao di·ªán
        st.session_state.df_features = df_all_features
        
        # L∆∞u d√≤ng k·∫øt qu·∫£ ƒë·ªÉ hi·ªÉn th·ªã ngay d∆∞·ªõi form
        result_display = df_all_features.tail(1).copy()
        result_display['Date'] = result_display['Date'].dt.strftime('%d/%m/%Y')
        for col in result_display.columns:
            if col != 'Date' and col != 'Vol':
                result_display[col] = result_display[col].apply(lambda x: f"${x:.4f}" if pd.notna(x) else "N/A")
        
        st.session_state.last_manual_result = result_display
        st.success(f"ƒê√£ c·∫≠p nh·∫≠t to√†n b·ªô ch·ªâ s·ªë v√† d·ª± b√°o v√†o file CSV!")
        st.rerun()
        
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu: {e}")
        import traceback
        st.error(traceback.format_exc())


def display_layer2_content():
    """Display Layer 2 (Within-day prediction) content"""
    # --- H√ÄNG 1: NH·∫¨P LI·ªÜU & HU·∫§N LUY·ªÜN LAYER 2 ---
    col_top_left, col_top_right = st.columns([1, 1.8])
    
    with col_top_left:
        st.markdown('<div class="section-header">1. NH·∫¨P D·ªÆ LI·ªÜU</div>', unsafe_allow_html=True)
        with st.container(border=True):
            uploaded_file_l2 = st.file_uploader("CSV/Excel file (L2)", type=['csv', 'xlsx'], key="file_l2", label_visibility="collapsed")
            if st.button("X·ª≠ l√Ω", use_container_width=True, type="primary", key="btn_process_l2", disabled=(uploaded_file_l2 is None)):
                load_and_process_data(uploaded_file_l2)
                
    with col_top_right:
        st.markdown('<div class="section-header">2. HU·∫§N LUY·ªÜN LAYER 2</div>', unsafe_allow_html=True)
        with st.container(border=True):
            ridge_status = "ƒê√£ train" if st.session_state.get('l2_ridge_model_trained', False) else "Ch∆∞a train"
            st.caption(f"Tr·∫°ng th√°i Layer 2: Ridge Stacking [{ridge_status}]")
            
            col_l2_btn1, col_l2_btn2 = st.columns(2)
            with col_l2_btn1:
                if st.button("Train Layer 2", use_container_width=True, type="primary", key="btn_train_l2", disabled=not st.session_state.model_trained):
                    train_layer2_logic()
            with col_l2_btn2:
                if st.button("Load L2 Models", use_container_width=True, key="btn_load_l2"):
                    load_l2_model()

    st.markdown("---")
    
    if st.session_state.df_features is None:
        st.info("Vui l√≤ng t·∫£i d·ªØ li·ªáu ·ªü M·ª•c 1 ho·∫∑c Sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
        return

    # Prediction Section
    st.subheader("D·ª± ƒëo√°n gi√° ch·ªët phi√™n tr·ª±c tuy·∫øn")
    
    # 1. Get Base Predictions from Layer 1 for the TARGET day
    latest_row = st.session_state.df_features.iloc[-1]
    last_date = latest_row['Date']
    target_date = get_next_trading_date(last_date)
    
    # Check if we have fresh predictions
    l1_rf_target = None
    l1_svr_target = None
    
    # Try getting from row first
    if 'RF_Pred_Tomorrow' in latest_row and pd.notna(latest_row['RF_Pred_Tomorrow']):
        l1_rf_target = latest_row['RF_Pred_Tomorrow']
    if 'SVR_Pred_Tomorrow' in latest_row and pd.notna(latest_row['SVR_Pred_Tomorrow']):
        l1_svr_target = latest_row['SVR_Pred_Tomorrow']
        
    # Overwrite/fill from session if user just clicked predict
    if 'prediction' in st.session_state:
        if st.session_state.prediction['date'].date() == target_date.date():
            results = st.session_state.prediction['results']
            if 'RF' in results: l1_rf_target = results['RF']['price']
            if 'SVR' in results: l1_svr_target = results['SVR']['price']

    if l1_rf_target is None or l1_svr_target is None:
        st.warning(f"Ch∆∞a c√≥ ƒë·ªß d·ª± ƒëo√°n Layer 1 (RF & SVR) cho ng√†y {target_date.strftime('%d/%m/%Y')}. Vui l√≤ng qua Tab Layer 1 hu·∫•n luy·ªán v√† d·ª± ƒëo√°n c·∫£ 2 m√¥ h√¨nh tr∆∞·ªõc.")
        return

    # --- Layer 1 Summary Dashboard ---
    st.markdown(f"""
    <div style="background-color: #F9FAFB; border: 1px solid #E5E7EB; border-radius: 12px; padding: 15px; margin-bottom: 20px;">
        <div style="display: flex; align-items: center; margin-bottom: 12px;">
            <div style="width: 4px; height: 18px; background-color: #007BFF; margin-right: 10px; border-radius: 2px;"></div>
            <div style="font-weight: 700; color: #1F2937; font-size: 0.9rem; text-transform: uppercase;">Th√¥ng tin t·ª´ Layer 1 (T√≠nh nƒÉng ƒë·∫ßu v√†o)</div>
        </div>
        <div style="display: grid; grid-template-columns: repeat(3, 1fr); gap: 15px;">
            <div style="background: white; padding: 10px; border-radius: 8px; border: 1px solid #F3F4F6; text-align: center;">
                <div style="font-size: 0.7rem; color: #6B7280; text-transform: uppercase; letter-spacing: 0.5px;">Ng√†y m·ª•c ti√™u</div>
                <div style="font-size: 1rem; font-weight: 600; color: #111827;">{target_date.strftime('%d/%m/%Y')}</div>
            </div>
            <div style="background: white; padding: 10px; border-radius: 8px; border: 1px solid #F3F4F6; text-align: center;">
                <div style="font-size: 0.7rem; color: #6B7280; text-transform: uppercase; letter-spacing: 0.5px;">RF_Pred_Today</div>
                <div style="font-size: 1rem; font-weight: 600; color: #00b894;">${format_number(l1_rf_target)}</div>
            </div>
            <div style="background: white; padding: 10px; border-radius: 8px; border: 1px solid #F3F4F6; text-align: center;">
                <div style="font-size: 0.7rem; color: #6B7280; text-transform: uppercase; letter-spacing: 0.5px;">SVR_Pred_Today</div>
                <div style="font-size: 1rem; font-weight: 600; color: #00b894;">${format_number(l1_svr_target)}</div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # 2. User Input
    with st.form("layer2_form"):
        st.write(f"Nh·∫≠p d·ªØ li·ªáu th·ªã tr∆∞·ªùng th·ª±c t·∫ø c·ªßa ng√†y {target_date.strftime('%d/%m/%Y')}:")
        col1, col2 = st.columns(2)
        with col1:
            open_price = st.number_input("Gi√° m·ªü c·ª≠a (Open)", value=None, placeholder="Nh·∫≠p gi√° m·ªü c·ª≠a...", format="%.4f")
            high_price = st.number_input("Gi√° cao nh·∫•t (High)", value=None, placeholder="Nh·∫≠p gi√° cao nh·∫•t...", format="%.4f")
        with col2:
            low_price = st.number_input("Gi√° th·∫•p nh·∫•t (Low)", value=None, placeholder="Nh·∫≠p gi√° th·∫•p nh·∫•t...", format="%.4f")
            current_vol = st.number_input("Kh·ªëi l∆∞·ª£ng d·ª± ki·∫øn (Volume)", value=None, placeholder="Nh·∫≠p kh·ªëi l∆∞·ª£ng d·ª± ki·∫øn...", format="%.0f")
        
        submit = st.form_submit_button("T√≠nh to√°n gi√° ch·ªët phi√™n (Layer 2)")

    if submit:
        if any(v is None for v in [open_price, high_price, low_price, current_vol]):
            st.error("Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß gi√° Open, High, Low v√† Volume c·ªßa ng√†y h√¥m nay!")
        elif not st.session_state.l2_ridge_model_trained:
            st.error("Vui l√≤ng train Layer 2 t·∫°i Tab n√†y tr∆∞·ªõc!")
        else:
            try:
                # Combine Features: [Open, High, Low, Vol, RF_Pred_Today, SVR_Pred_Today]
                l2_input = np.array([[open_price, high_price, low_price, current_vol, l1_rf_target, l1_svr_target]])
                
                pred_close = predict_layer2(st.session_state.l2_ridge_model, st.session_state.l2_ridge_scaler, l2_input)
                
                st.markdown(f"""
                <div class="prediction-card" style="max-width: 500px; margin: 0 auto;">
                    <div class="pred-title">L2: Ridge Stacking Result</div>
                    <div class="pred-sub">Gi√° ch·ªët phi√™n h·ªôi t·ª• (D·ª±a tr√™n O-H-L-V & L1 Hybrid)</div>
                    <div class="pred-price" style="color: #007BFF; font-size: 2.5rem;">${format_number(pred_close)}</div>
                    <div class="confidence-box" style="background-color: #ebf5ff;">
                        <span style="font-size: 0.9rem; color: #007BFF; font-weight: 600;">K·∫øt h·ª£p t·ªëi ∆∞u t·ª´ Random Forest v√† Support Vector Regressor</span>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
            except Exception as e:
                st.error(f"L·ªói d·ª± ƒëo√°n L2: {e}")

def train_layer2_logic():
    """Train Layer 2 (Single Ridge Stacking)"""
    with st.spinner("ƒêang chu·∫©n b·ªã d·ªØ li·ªáu v√† hu·∫•n luy·ªán Layer 2..."):
        try:
            if st.session_state.df_features is None:
                st.error("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc!")
                return

            # Check L1 models
            if not st.session_state.model_trained or not st.session_state.svr_model_trained:
                st.error("C·∫ßn hu·∫•n luy·ªán c·∫£ RandomForest v√† SVR (Layer 1) tr∆∞·ªõc khi train Layer 2!")
                return

            df = st.session_state.df_features.copy()
            feature_cols = st.session_state.feature_cols
            
            # --- Generate L1 Projections for History ---
            df_to_pred = df[feature_cols].copy().replace([np.inf, -np.inf], np.nan).ffill().fillna(0)
            X_all = df_to_pred.values
            
            # 1. RF Predictions
            rf_scaler = st.session_state.scaler
            rf_model = st.session_state.model
            X_scaled_rf = rf_scaler.transform(X_all)
            df['RF_Pred_Tomorrow'] = rf_model.predict(X_scaled_rf)
            df['RF_Pred_Today'] = df['RF_Pred_Tomorrow'].shift(1)
            
            # 2. SVR Predictions
            svr_scaler = st.session_state.svr_scaler
            svr_model = st.session_state.svr_model
            X_scaled_svr = svr_scaler.transform(X_all)
            df['SVR_Pred_Tomorrow'] = svr_model.predict(X_scaled_svr)
            df['SVR_Pred_Today'] = df['SVR_Pred_Tomorrow'].shift(1)
            
            # Update session state with L1 history
            st.session_state.df_features = df
            
            # --- Prepare L2 Stacking Data ---
            # Inputs: Open, High, Low, Vol, RF_Pred_Today, SVR_Pred_Today
            l2_features = ['Open', 'High', 'Low', 'Vol', 'RF_Pred_Today', 'SVR_Pred_Today']
            target = 'Price'
            
            # Drop NaNs from shifting
            df_l2 = df.dropna(subset=l2_features + [target])
            
            if len(df_l2) < 50:
                st.error("Kh√¥ng ƒë·ªß d·ªØ li·ªáu s·∫°ch ƒë·ªÉ train Layer 2 (thi·∫øu l·ªãch s·ª≠ d·ª± b√°o).")
                return
                
            X = df_l2[l2_features]
            y = df_l2[target]
            
            # Split (80/20)
            split_idx = int(len(X) * 0.8)
            X_train, y_train = X[:split_idx], y[:split_idx]
            
            # Train Single Ridge Model
            ridge_model, ridge_scaler = train_layer2_model(X_train, y_train)
            
            # Save
            save_model(ridge_model, L2_RIDGE_MODEL_PATH)
            save_model(ridge_scaler, L2_RIDGE_SCALER_PATH)
            
            # Update Session State
            st.session_state.l2_ridge_model = ridge_model
            st.session_state.l2_ridge_scaler = ridge_scaler
            st.session_state.l2_ridge_model_trained = True
            
            st.toast("ƒê√£ train Layer 2 (Single Ridge Stacking) th√†nh c√¥ng!")
            
        except Exception as e:
            st.error(f"L·ªói khi train L2: {e}")
            import traceback
            st.error(traceback.format_exc())

def load_l2_model():
    """Load Layer 2 model (Single Ridge Stacking)"""
    with st.spinner("ƒêang t·∫£i m√¥ h√¨nh Layer 2..."):
        try:
            ridge_model = load_model(L2_RIDGE_MODEL_PATH)
            ridge_scaler = load_model(L2_RIDGE_SCALER_PATH)
            if ridge_model and ridge_scaler:
                st.session_state.l2_ridge_model = ridge_model
                st.session_state.l2_ridge_scaler = ridge_scaler
                st.session_state.l2_ridge_model_trained = True
                st.toast("ƒê√£ t·∫£i m√¥ h√¨nh Layer 2 Ridge Stacking th√†nh c√¥ng!")
            else:
                st.warning("Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh Layer 2 ƒë√£ l∆∞u.")
        except Exception as e:
            st.error(f"L·ªói khi load L2 model: {e}")


def display_keras_lstm_impl():
    """Hi·ªÉn th·ªã n·ªôi dung cho Layer 3 (LSTM) - Keras Implementation"""
    st.subheader("Layer 3: D·ª± b√°o chu·ªói th·ªùi gian b·∫±ng Deep Learning (LSTM)")
    
    # Cho ph√©p ch·ªçn file CSV ri√™ng cho Layer 3
    st.markdown("### Ch·ªçn d·ªØ li·ªáu cho Layer 3")
    l3_file = st.file_uploader("T·∫£i l√™n file CSV (V√≠ d·ª•: ETHUSDT.csv)", type=['csv'])
    
    if l3_file is not None:
        if st.button("S·ª≠ d·ª•ng file ƒë√£ t·∫£i l√™n cho Layer 3"):
            load_l3_custom_data(l3_file)
            
    st.markdown("---")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        if st.button("X·ª≠ l√Ω d·ªØ li·ªáu L3", use_container_width=True):
            prepare_l3_features()
    with col2:
        if st.button("Train m√¥ h√¨nh L3", use_container_width=True):
            train_l3_model()
    with col3:
        if st.button("Load L3 model", use_container_width=True):
            load_l3_model()
    with col4:
        if st.button("D·ª± b√°o LSTM (7 ng√†y)", use_container_width=True, disabled=not st.session_state.l3_model_trained):
            make_l3_prediction()

    st.markdown("---")
    
    if 'l3_prediction' in st.session_state:
        display_l3_prediction_results()
    else:
        st.info("S·ª≠ d·ª•ng LSTM ƒë·ªÉ d·ª± b√°o bi·∫øn ƒë·ªông gi√° trong 7 ng√†y t·ªõi d·ª±a tr√™n 30 ng√†y l·ªãch s·ª≠.")
        
    if st.checkbox("Hi·ªÉn th·ªã ki·∫øn tr√∫c m√¥ h√¨nh LSTM"):
        st.code("""
        Model: Sequential
        Layer 1: LSTM (64 units, return_sequences=True)
        Layer 2: Dropout (0.2)
        Layer 3: LSTM (32 units)
        Layer 4: Dropout (0.2)
        Layer 5: Dense (7 units - forecast window)
        Optimizer: Adam (lr=0.001)
        Loss: MSE
        """)

def load_l3_custom_data(uploaded_file):
    """Load d·ªØ li·ªáu t·ª´ file upload cho Layer 3"""
    try:
        df = pd.read_csv(uploaded_file)
        # Standardize columns
        if 'Date' in df.columns:
            df['Date'] = pd.to_datetime(df['Date'])
        
        # Mapping common column names if needed
        col_map = {
            'Close': 'Price',
            'Volume': 'Vol'
        }
        df = df.rename(columns=col_map)
        
        # Basic requirements
        required = ['Date', 'Price', 'Open', 'High', 'Low', 'Vol']
        if all(col in df.columns for col in required):
            st.session_state.df_l3_raw = df[required]
            st.toast(f"ƒê√£ t·∫£i d·ªØ li·ªáu cho Layer 3!", icon="üì•")
            st.dataframe(df.head())
        else:
            st.error(f"File CSV thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: {required}")
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω file: {e}")

def prepare_l3_features():
    """T·∫°o features cho LSTM"""
    # ∆Øu ti√™n s·ª≠ d·ª•ng d·ªØ li·ªáu ri√™ng c·ªßa L3 n·∫øu c√≥, n·∫øu kh√¥ng l·∫•y t·ª´ main df
    if 'df_l3_raw' in st.session_state:
        df = st.session_state.df_l3_raw.copy()
    elif st.session_state.df_features is not None:
        df = st.session_state.df_features[['Date', 'Price', 'Open', 'High', 'Low', 'Vol']]
    else:
        st.error("Vui l√≤ng t·∫£i d·ªØ li·ªáu ho·∫∑c ch·ªçn file CSV!")
        return
        
    with st.spinner("ƒêang t√≠nh to√°n technical indicators cho LSTM..."):
        try:
            df_l3 = create_lstm_features(df)
            st.session_state.df_l3 = df_l3
            st.toast("‚úì ƒê√£ chu·∫©n b·ªã features cho LSTM!", icon="‚öôÔ∏è")
            st.dataframe(df_l3.tail(5))
        except Exception as e:
            st.error(f"L·ªói: {e}")

def train_l3_model():
    """Train LSTM model"""
    if 'df_l3' not in st.session_state:
        prepare_l3_features()
        
    df = st.session_state.df_l3.copy()
    feature_cols = ['Open', 'High', 'Low', 'Price', 'Vol', 'VVR', 'VWAP', 
                    'Lag_1', 'Lag_2', 'Lag_3', 'Lag_5', 'Lag_7', 
                    'Price_Change', 'Volatility', 'MA5', 'MA10']
    
    df_clean = df.dropna(subset=feature_cols)
    
    with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh LSTM (Deep Learning)..."):
        try:
            X, y, scaler, target_scaler = prepare_lstm_data(df_clean, feature_cols)
            
            # Split
            n = len(X)
            split = int(n * 0.9)
            X_train, y_train = X[:split], y[:split]
            
            model = train_lstm_model(X_train, y_train)
            
            # Save
            model.save(L3_MODEL_PATH)
            save_model(scaler, L3_SCALER_PATH)
            save_model(target_scaler, L3_TARGET_SCALER_PATH)
            
            st.session_state.l3_model = model
            st.session_state.l3_scaler = scaler
            st.session_state.l3_target_scaler = target_scaler
            st.session_state.l3_model_trained = True
            st.session_state.l3_feature_cols = feature_cols
            
            st.toast("‚úì Hu·∫•n luy·ªán Layer 3 th√†nh c√¥ng!", icon="üöÄ")
        except Exception as e:
            st.error(f"L·ªói khi train LSTM: {e}")

def load_l3_model():
    """Load pre-trained LSTM model"""
    with st.spinner("ƒêang load m√¥ h√¨nh LSTM..."):
        try:
            from tensorflow.keras.models import load_model as load_keras_model
            if os.path.exists(L3_MODEL_PATH):
                st.session_state.l3_model = load_keras_model(L3_MODEL_PATH)
                st.session_state.l3_scaler = load_model(L3_SCALER_PATH)
                st.session_state.l3_target_scaler = load_model(L3_TARGET_SCALER_PATH)
                st.session_state.l3_model_trained = True
                st.session_state.l3_feature_cols = ['Open', 'High', 'Low', 'Price', 'Vol', 'VVR', 'VWAP', 
                                                'Lag_1', 'Lag_2', 'Lag_3', 'Lag_5', 'Lag_7', 
                                                'Price_Change', 'Volatility', 'MA5', 'MA10']
                st.toast("‚úì ƒê√£ load Layer 3 th√†nh c√¥ng!", icon="üíæ")
            else:
                st.warning("Kh√¥ng t√¨m th·∫•y t·ªáp m√¥ h√¨nh Layer 3.")
        except Exception as e:
            st.error(f"L·ªói: {e}")

def make_l3_prediction():
    """D·ª± b√°o 7 ng√†y t·ªõi b·∫±ng LSTM"""
    if not st.session_state.l3_model_trained:
        st.error("M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán ho·∫∑c load!")
        return
        
    try:
        df = st.session_state.df_l3.copy()
        feature_cols = st.session_state.l3_feature_cols
        
        # L·∫•y 30 ng√†y cu·ªëi ƒë·ªÉ l√†m sequence ƒë·∫ßu v√†o
        last_30_days = df.dropna(subset=feature_cols).tail(30)
        scaled_sequence = st.session_state.l3_scaler.transform(last_30_days[feature_cols])
        
        # Predict
        pred_scaled = predict_lstm(st.session_state.l3_model, scaled_sequence)
        
        # Inverse transform
        pred_prices = st.session_state.l3_target_scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()
        
        # Dates
        last_date = df['Date'].max()
        pred_dates = [last_date + timedelta(days=i) for i in range(1, 8)]
        
        pred_df = pd.DataFrame({
            'Date': pred_dates,
            'Predicted_Price': pred_prices
        })
        
        st.session_state.l3_prediction = pred_df
        st.toast("‚úì ƒê√£ ho√†n th√†nh d·ª± b√°o LSTM!", icon="üîÆ")
        
    except Exception as e:
        st.error(f"L·ªói khi d·ª± b√°o LSTM: {e}")

def display_l3_prediction_results():
    """Hi·ªÉn th·ªã k·∫øt qu·∫£ d·ª± b√°o c·ªßa LSTM"""
    pred_df = st.session_state.l3_prediction
    
    # X√°c ƒë·ªãnh ngu·ªìn d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã l·ªãch s·ª≠
    if 'df_l3' in st.session_state:
        df_source = st.session_state.df_l3
    elif 'df_l3_raw' in st.session_state:
        df_source = st.session_state.df_l3_raw
    elif st.session_state.df_features is not None:
        df_source = st.session_state.df_features
    else:
        st.warning("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ ƒë·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì.")
        return

    df_hist = df_source.tail(20)
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("B·∫£ng d·ª± ƒëo√°n 7 ng√†y")
        fmt_df = pred_df.copy()
        fmt_df['Date'] = fmt_df['Date'].dt.strftime('%d/%m/%Y')
        fmt_df['Predicted_Price'] = fmt_df['Predicted_Price'].map('${:,.4f}'.format)
        st.table(fmt_df)
        
    with col2:
        st.subheader("Bi·ªÉu ƒë·ªì d·ª± b√°o Deep Learning")
        fig = go.Figure()
        
        # L·ªãch s·ª≠
        fig.add_trace(go.Scatter(
            x=df_hist['Date'], y=df_hist['Price'],
            mode='lines+markers', name='L·ªãch s·ª≠ (20 ng√†y)',
            line=dict(color='white')
        ))
        
        # D·ª± b√°o
        # N·ªëi ƒëi·ªÉm cu·ªëi l·ªãch s·ª≠ v·ªõi ƒëi·ªÉm ƒë·∫ßu d·ª± b√°o
        connect_date = [df_hist['Date'].iloc[-1]] + pred_df['Date'].tolist()
        connect_price = [df_hist['Price'].iloc[-1]] + pred_df['Predicted_Price'].tolist()
        
        fig.add_trace(go.Scatter(
            x=connect_date, y=connect_price,
            mode='lines+markers', name='LSTM Forecast',
            line=dict(color='#00D9FF', dash='dash', width=3)
        ))
        
        fig.update_layout(
            template='plotly_dark',
            margin=dict(l=10, r=10, t=30, b=10),
            height=450,
            xaxis_title="Ng√†y",
            yaxis_title="Gi√° XRP ($)",
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
        )
        
        st.plotly_chart(fig, use_container_width=True)


# Layer 3 Enhanced Content - Append this to app.py before if __name__ == "__main__"

# =============================================================================
# LAYER 3: ENHANCED WITH REGIME LSTM \u0026 ML ENSEMBLE
# =============================================================================

def display_layer3_content():
    """
    Enhanced Layer 3 v·ªõi 3 ph∆∞∆°ng ph√°p h·ªçc chu·ªói:
    - Tab 1: LSTM (Keras) - Hi·ªán t·∫°i
    - Tab 2: Regime LSTM - Custom implementation v·ªõi regime detection
    - Tab 3: ML Ensemble - RandomForest + GradientBoosting + Ridge
    """
    
    # st.markdown('\u003cdiv class="section-header"\u003eL·ªöP 3: H·ªåC S√ÇU \u0026 SEQUENCE LEARNING\u003c/div\u003e', unsafe_allow_html=True)
    
    # Removed dependency check to allow custom file upload in sub-tabs
    
    # Create 3 tabs
    # Create 2 tabs (Hidden Keras LSTM)
    tab_regime, tab_ensemble = st.tabs([
        "üü† Regime LSTM", 
        "üü¢ ML Ensemble"
    ])
    
    # ===================
    # TAB 1: Keras LSTM (Hidden as requested)
    # ===================
    # with tab_keras:
    #     display_keras_lstm_tab()
    
    # ===================
    # TAB 2: Regime LSTM (NEW)
    # ===================
    with tab_regime:
        display_regime_lstm_tab()
    
    # ===================
    # TAB 3: ML Ensemble (NEW)
    # ===================
    with tab_ensemble:
        display_ml_ensemble_tab()


def display_keras_lstm_tab():
    """Tab c≈© - LSTM Keras hi·ªán t·∫°i"""
    # G·ªçi h√†m th·ª±c thi logic c≈©
    display_keras_lstm_impl()


def display_regime_lstm_tab():
    """Tab m·ªõi - Regime-aware LSTM theo ƒë√∫ng lu·ªìng LSTMCustom.ipynb"""
    st.subheader("Regime LSTM - Nh·∫≠n di·ªán ch·∫ø ƒë·ªô volatility")
    
    # --- H√ÄNG 1: NH·∫¨P LI·ªÜU & HU·∫§N LUY·ªÜN ---
    col_top_left, col_top_right = st.columns([1, 1.8])
    
    with col_top_left:
        st.markdown('<div class="section-header">1. NH·∫¨P D·ªÆ LI·ªÜU</div>', unsafe_allow_html=True)
        with st.container(border=True):
            regime_file = st.file_uploader("T·∫£i l√™n file CSV", type=['csv'], key="regime_uploader", label_visibility="collapsed")
            
            if regime_file is not None:
                try:
                    df_r = pd.read_csv(regime_file)
                    if 'Date' in df_r.columns:
                        df_r['Date'] = pd.to_datetime(df_r['Date'])
                        df_r = df_r.sort_values('Date').reset_index(drop=True)
                    
                    col_map = {'Close': 'Price', 'Volume': 'Vol', 'high': 'High', 'low': 'Low', 'open': 'Open'}
                    for old_col, new_col in col_map.items():
                        if old_col in df_r.columns and new_col not in df_r.columns:
                            df_r.rename(columns={old_col: new_col}, inplace=True)
                    
                    required_cols = ['Price', 'Vol', 'High', 'Low']
                    missing = [c for c in required_cols if c not in df_r.columns]
                    if missing:
                        st.error(f"Thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: {', '.join(missing)}")
                    else:
                        st.session_state.df_regime_raw = df_r
                        st.toast(f"‚úì ƒê√£ t·∫£i {len(df_r)} d√≤ng d·ªØ li·ªáu g·ªëc.")
                except Exception as e:
                    st.error(f"L·ªói t·∫£i file: {e}")
            
            col_reg_btn1, col_reg_btn2 = st.columns(2)
            with col_reg_btn1:
                if st.button("X·ª≠ l√Ω Features", type="primary", use_container_width=True, key="btn_reg_process", disabled='df_regime_raw' not in st.session_state):
                    with st.spinner("ƒêang t√≠nh to√°n ƒë·∫∑c tr∆∞ng..."):
                        df_features = create_regime_features(st.session_state.df_regime_raw)
                        st.session_state.df_regime = df_features
                        st.toast("‚úì ƒê√£ t·∫°o xong 18 features!")
            with col_reg_btn2:
                if st.button("Xem Data", use_container_width=True, key="btn_reg_view", disabled='df_regime' not in st.session_state):
                    st.session_state.show_regime_data = not st.session_state.get('show_regime_data', False)

    with col_top_right:
        st.markdown('<div class="section-header">2. HU·∫§N LUY·ªÜN</div>', unsafe_allow_html=True)
        with st.container(border=True):
            status_text = "ƒê√£ train" if st.session_state.get('regime_lstm_trained', False) else "Ch∆∞a train"
            st.caption(f"Tr·∫°ng th√°i m√¥ h√¨nh: {status_text}")
            
            col_train_l, col_train_r = st.columns(2)
            with col_train_l:
                with st.expander("Tham s·ªë training", expanded=False):
                    reg_epochs = st.slider("Epochs", 20, 150, 70, 10, key="reg_ep")
                    reg_lr = st.number_input("Learning rate", 0.0001, 0.01, 0.001, format="%.4f", key="reg_lr")
                if st.button("B·∫Øt ƒë·∫ßu Train", type="primary", use_container_width=True, key="btn_reg_train", disabled='df_regime' not in st.session_state):
                    train_regime_lstm_model(reg_epochs, reg_lr)
            
            with col_train_r:
                st.write("") # Spacer
                if st.button("T·∫£i model t·ª´ disk", use_container_width=True, key="btn_reg_load"):
                    load_regime_lstm_model_from_disk()

    if st.session_state.get('show_regime_data', False) and 'df_regime' in st.session_state:
        st.dataframe(st.session_state.df_regime.tail(100), use_container_width=True, height=250)

    st.markdown("---")
    
    # --- PH·∫¶N K·∫æT QU·∫¢ D·ª∞ B√ÅO ---
    if st.session_state.regime_lstm_trained:
        col_res1, col_res2 = st.columns([1, 2])
        with col_res1:
            st.markdown('<div class="section-header">3. D·ª∞ B√ÅO T+7</div>', unsafe_allow_html=True)
            if st.button("Th·ª±c hi·ªán D·ª± b√°o", type="primary", use_container_width=True, key="btn_reg_pred"):
                make_regime_lstm_prediction()
        
        if st.session_state.regime_lstm_metrics is not None:
            display_regime_lstm_results()
    else:
        st.info("Vui l√≤ng x·ª≠ l√Ω d·ªØ li·ªáu v√† hu·∫•n luy·ªán m√¥ h√¨nh ƒë·ªÉ d·ª± b√°o.")


def display_ml_ensemble_tab():
    st.subheader("ML Ensemble - Stacking Approach")
    
    # --- H√ÄNG 1: NH·∫¨P LI·ªÜU & HU·∫§N LUY·ªÜN ---
    col_top_left, col_top_right = st.columns([1, 1.8])
    
    with col_top_left:
        st.markdown('<div class="section-header">1. NH·∫¨P D·ªÆ LI·ªÜU</div>', unsafe_allow_html=True)
        with st.container(border=True):
            ensemble_file = st.file_uploader("T·∫£i l√™n file CSV", type=['csv'], key="ensemble_uploader", label_visibility="collapsed")
            
            if ensemble_file is not None:
                try:
                    df_e = pd.read_csv(ensemble_file)
                    if 'Date' in df_e.columns:
                        df_e['Date'] = pd.to_datetime(df_e['Date'])
                        df_e = df_e.sort_values('Date').reset_index(drop=True)
                    if 'Close' in df_e.columns and 'Price' not in df_e.columns:
                        df_e.rename(columns={'Close': 'Price'}, inplace=True)
                    if 'Volume' in df_e.columns and 'Vol' not in df_e.columns:
                        df_e.rename(columns={'Volume': 'Vol'}, inplace=True)
                    st.session_state.df_ensemble_raw = df_e
                    st.toast("‚úì ƒê√£ nh·∫≠n file CSV cho Ensemble.")
                except Exception as e:
                    st.error(f"L·ªói t·∫£i file: {e}")
            
            col_ens_btn1, col_ens_btn2 = st.columns(2)
            with col_ens_btn1:
                # Resolve data source (Independent only)
                data_ready = 'df_ensemble_raw' in st.session_state

                if st.button("X·ª≠ l√Ω Features", type="primary", use_container_width=True, key="btn_ens_process", disabled=not data_ready):
                    with st.spinner("ƒêang t·∫°o features..."):
                        source_df = st.session_state.df_ensemble_raw
                        df_processed = create_ml_features(source_df)
                        st.session_state.df_ensemble = df_processed
                        st.toast("‚úì ƒê√£ chu·∫©n b·ªã features cho Ensemble!")
            with col_ens_btn2:
                if st.button("Xem Data", use_container_width=True, key="btn_ens_view", disabled='df_ensemble' not in st.session_state):
                    st.session_state.show_ensemble_data = not st.session_state.get('show_ensemble_data', False)

    with col_top_right:
        st.markdown('<div class="section-header">2. HU·∫§N LUY·ªÜN</div>', unsafe_allow_html=True)
        with st.container(border=True):
            status_text = "ƒê√£ train" if st.session_state.get('ml_ensemble_trained', False) else "Ch∆∞a train"
            st.caption(f"Tr·∫°ng th√°i m√¥ h√¨nh: {status_text}")
            
            col_e_train1, col_e_train2 = st.columns(2)
            with col_e_train1:
                if st.button("Train Ensemble", type="primary", use_container_width=True, key="btn_ens_train", disabled='df_ensemble' not in st.session_state):
                    train_ml_ensemble_model()
            with col_e_train2:
                if st.button("T·∫£i model t·ª´ disk", use_container_width=True, key="btn_ens_load"):
                    load_ml_ensemble_model_from_disk()

    if st.session_state.get('show_ensemble_data', False) and 'df_ensemble' in st.session_state:
        st.dataframe(st.session_state.df_ensemble.tail(100), use_container_width=True, height=250)

    st.markdown("---")
    
    # --- PH·∫¶N K·∫æT QU·∫¢ D·ª∞ B√ÅO ---
    if st.session_state.ml_ensemble_trained:
        col_res1, col_res2 = st.columns([1, 2])
        with col_res1:
            st.markdown('<div class="section-header">3. D·ª∞ B√ÅO T+7</div>', unsafe_allow_html=True)
            if st.button("Th·ª±c hi·ªán D·ª± b√°o", type="primary", use_container_width=True, key="btn_ens_pred"):
                make_ml_ensemble_prediction()
        
        if st.session_state.ml_ensemble_metrics is not None:
             display_ml_ensemble_results()
    else:
        st.info("Vui l√≤ng t·∫£i file CSV ri√™ng trong Tab n√†y ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh Ensemble.")
    
    st.divider()
    
    # Display results
    if st.session_state.ml_ensemble_metrics is not None:
        display_ml_ensemble_results()


# ======================
# TRAINING FUNCTIONS
# ======================

def train_regime_lstm_model(epochs=60, lr=0.001):
    """Train Regime LSTM model"""
    with st.spinner(f"ƒêang training Regime LSTM ({epochs} epochs)..."):
        try:
            # L·∫•y d·ªØ li·ªáu ri√™ng c·ªßa Regime Tab
            if 'df_regime' in st.session_state and st.session_state.df_regime is not None:
                df = st.session_state.df_regime.copy()
            else:
                st.error("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu cho Regime LSTM! Vui l√≤ng t·∫£i file CSV ·ªü B∆∞·ªõc 1 (trong Tab n√†y).")
                return
            
            # Ensure required columns
            if 'Price' not in df.columns:
                st.error("D·ªØ li·ªáu thi·∫øu c·ªôt 'Price'!")
                return
            
            # ƒê·∫£m b·∫£o d·ªØ li·ªáu ƒë∆∞·ª£c s·∫Øp x·∫øp theo th·ªùi gian tƒÉng d·∫ßn
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'])
                df = df.sort_values('Date').reset_index(drop=True)
            
            # Validate that features have been created (Regime specific)
            if 'vol_z' not in df.columns:
                st.warning("‚ö†Ô∏è D·ªØ li·ªáu ch∆∞a c√≥ regime features. ƒêang t·ª± ƒë·ªông x·ª≠ l√Ω...")
                from utils.regime_lstm import create_regime_features
                df = create_regime_features(df)
                st.success("‚úì ƒê√£ x·ª≠ l√Ω regime features t·ª± ƒë·ªông")
            
            # Train model
            model, scalers, metrics = train_regime_lstm(
                df, 
                epochs=epochs, 
                lr=lr, 
                lookback=30, 
                horizon=7,
                test_size=0.2,
                verbose=True
            )
            
            # Save to session
            st.session_state.regime_lstm_model = model
            st.session_state.regime_lstm_scalers = scalers
            st.session_state.regime_lstm_metrics = metrics
            st.session_state.regime_lstm_trained = True
            
            # Save to disk
            save_model(model, REGIME_LSTM_MODEL_PATH)
            save_model(scalers, REGIME_LSTM_SCALERS_PATH)
            
            st.toast(f"‚úì Training ho√†n t·∫•t! MAE: {metrics['mae']:.4f}")
            
        except Exception as e:
            st.error(f"L·ªói khi training: {e}")
            import traceback
            st.error(traceback.format_exc())


def train_ml_ensemble_model():
    """Train ML Ensemble model"""
    with st.spinner("ƒêang training ML Ensemble..."):
        try:
            # L·∫•y d·ªØ li·ªáu ri√™ng c·ªßa Ensemble Tab
            if 'df_ensemble' in st.session_state and st.session_state.df_ensemble is not None:
                df = st.session_state.df_ensemble.copy()
            else:
                st.error("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu cho ML Ensemble! Vui l√≤ng t·∫£i file CSV ·ªü B∆∞·ªõc 1 (trong Tab n√†y).")
                return

            df.to_csv("df_features_export.csv", index=False)
            
            # ƒê·∫£m b·∫£o d·ªØ li·ªáu ƒë∆∞·ª£c s·∫Øp x·∫øp theo th·ªùi gian tƒÉng d·∫ßn
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'])
                df = df.sort_values('Date').reset_index(drop=True)
            
            # Validate that features have been created
            if 'RSI_14' not in df.columns:
                st.warning("D·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c x·ª≠ l√Ω features. ƒêang t·ª± ƒë·ªông x·ª≠ l√Ω...")
                from utils.ml_ensemble import create_ml_features
                df = create_ml_features(df)
                st.success("‚úì ƒê√£ x·ª≠ l√Ω features t·ª± ƒë·ªông")
            
            # Train model
            ensemble, metrics = train_ml_ensemble(
                df,
                lookback=30,
                horizon=7,
                train_ratio=0.8,
                verbose=False
            )
            
            # Save to session
            st.session_state.ml_ensemble_model = ensemble
            st.session_state.ml_ensemble_metrics = metrics
            st.session_state.ml_ensemble_trained = True
            
            # Save to disk
            save_model(ensemble, ML_ENSEMBLE_MODEL_PATH)
            
            mae = metrics['test']['mae']
            st.toast(f"‚úì Training ho√†n t·∫•t! MAE: {mae:.4f}", icon="üöÄ")
            
        except Exception as e:
            st.error(f"L·ªói khi training: {e}")
            st.error(traceback.format_exc())


def load_regime_lstm_model_from_disk():
    """Load Regime LSTM model from disk"""
    with st.spinner("ƒêang t·∫£i model Regime LSTM..."):
        try:
            model = load_model(REGIME_LSTM_MODEL_PATH)
            scalers = load_model(REGIME_LSTM_SCALERS_PATH)
            if model is not None and scalers is not None:
                st.session_state.regime_lstm_model = model
                st.session_state.regime_lstm_scalers = scalers
                st.session_state.regime_lstm_trained = True
                st.toast("ƒê√£ t·∫£i model Regime LSTM t·ª´ disk!")
            else:
                st.warning("Kh√¥ng t√¨m th·∫•y file model ƒë·ªÉ t·∫£i.")
        except Exception as e:
            st.error(f"L·ªói khi t·∫£i model: {e}")


def load_ml_ensemble_model_from_disk():
    """Load ML Ensemble model from disk"""
    with st.spinner("ƒêang t·∫£i model ML Ensemble..."):
        try:
            ensemble = load_model(ML_ENSEMBLE_MODEL_PATH)
            if ensemble is not None:
                st.session_state.ml_ensemble_model = ensemble
                st.session_state.ml_ensemble_trained = True
                st.toast("ƒê√£ t·∫£i model ML Ensemble t·ª´ disk!")
            else:
                st.warning("Kh√¥ng t√¨m th·∫•y file model ƒë·ªÉ t·∫£i.")
        except Exception as e:
            st.error(f"L·ªói khi t·∫£i model: {e}")


# ======================
# PREDICTION FUNCTIONS
# ======================

def make_regime_lstm_prediction():
    """Make prediction using Regime LSTM"""
    with st.spinner("ƒêang d·ª± b√°o v·ªõi Regime LSTM..."):
        try:
            # ∆Øu ti√™n d·ªØ li·ªáu ri√™ng
            if 'df_regime' in st.session_state and st.session_state.df_regime is not None:
                df = st.session_state.df_regime.copy()
            else:
                df = st.session_state.df_features.copy()
                
            # ƒê·∫£m b·∫£o s·∫Øp x·∫øp th·ªùi gian
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'])
                df = df.sort_values('Date').reset_index(drop=True)
            
            # Get latest 30+ rows for lookback
            df_latest = df.tail(35)  # Extra rows for feature engineering
            
            # Predict
            pred_price = predict_regime_lstm(
                st.session_state.regime_lstm_model,
                st.session_state.regime_lstm_scalers,
                df_latest,
                lookback=30
            )
            
            # Calculate predicted date (T+7)
            last_date = df.iloc[-1]['Date']
            pred_date = last_date + timedelta(days=7)
            
            # Store result
            if 'regime_lstm_prediction' not in st.session_state:
                st.session_state.regime_lstm_prediction = {}
            
            st.session_state.regime_lstm_prediction = {
                'date': pred_date,
                'price': pred_price,
                'current_price': df.iloc[-1]['Price']
            }
            
            st.success(f"D·ª± b√°o cho {pred_date.strftime('%d/%m/%Y')}: **${pred_price:.4f}**")
            
        except Exception as e:
            st.error(f"L·ªói khi d·ª± b√°o: {e}")
            import traceback
            st.error(traceback.format_exc())


def make_ml_ensemble_prediction():
    """Make prediction using ML Ensemble"""
    with st.spinner("ƒêang d·ª± b√°o v·ªõi ML Ensemble..."):
        try:
            # ∆Øu ti√™n d·ªØ li·ªáu ri√™ng
            if 'df_ensemble' in st.session_state and st.session_state.df_ensemble is not None:
                df = st.session_state.df_ensemble.copy()
            else:
                df = st.session_state.df_features.copy()
            
            # ƒê·∫£m b·∫£o s·∫Øp x·∫øp th·ªùi gian
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'])
                df = df.sort_values('Date').reset_index(drop=True)
            
            # Get latest 30+ rows
            df_latest = df.tail(60)  # Extra for MA calculations
            
            # Predict
            pred_price = st.session_state.ml_ensemble_model.predict_next(df_latest)
            
            # Calculate predicted date (T+7)
            last_date = df.iloc[-1]['Date']
            pred_date = last_date + timedelta(days=7)
            
            # Store result
            if 'ml_ensemble_prediction' not in st.session_state:
                st.session_state.ml_ensemble_prediction = {}
            
            st.session_state.ml_ensemble_prediction = {
                'date': pred_date,
                'price': pred_price,
                'current_price': df.iloc[-1].get('Close', df.iloc[-1].get('Price', 0))
            }
            
            st.success(f"D·ª± b√°o cho {pred_date.strftime('%d/%m/%Y')}: **${pred_price:.4f}**")
            
        except Exception as e:
            st.error(f"L·ªói khi d·ª± b√°o: {e}")
            import traceback
            st.error(traceback.format_exc())


# ======================
# RESULTS DISPLAY
# ======================

def display_regime_lstm_results():
    """Display Regime LSTM training \u0026 prediction results"""
    st.subheader("K·∫øt qu·∫£ Regime LSTM")
    
    metrics = st.session_state.regime_lstm_metrics
    
    # Metrics
    col1, col2 = st.columns(2)
    col1.metric("MAE (Test)", f"{metrics['mae']:.4f}")
    col2.metric("MSE (Test)", f"{metrics['mse']:.6f}")
    
    # Training loss curve
    if 'train_losses' in metrics:
        import plotly.graph_objects as go
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            y=metrics['train_losses'],
            mode='lines',
            name='Training Loss',
            line=dict(color='#FF6B6B')
        ))
        fig.update_layout(
            title="Training Loss Curve",
            xaxis_title="Epoch",
            yaxis_title="Loss (MSE)",
            template='plotly_white',
            height=300
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Actual vs Predicted plot (from notebook logic)
    if 'y_true' in metrics and 'y_pred' in metrics:
        import plotly.graph_objects as go
        
        fig_pred = go.Figure()
        fig_pred.add_trace(go.Scatter(
            y=metrics['y_true'],
            mode='lines',
            name='Actual (Test)',
            line=dict(color='gray', width=1)
        ))
        fig_pred.add_trace(go.Scatter(
            y=metrics['y_pred'],
            mode='lines',
            name='Predicted (Test)',
            line=dict(color='orange', width=2)
        ))
        fig_pred.update_layout(
            title="Actual vs Predicted (Test Set)",
            xaxis_title="Time Index",
            yaxis_title="Price",
            template='plotly_white',
            height=400,
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
        )
        st.plotly_chart(fig_pred, use_container_width=True)
    
    # Prediction display
    if 'regime_lstm_prediction' in st.session_state:
        pred = st.session_state.regime_lstm_prediction
        
        st.markdown(f"""
        \u003cdiv class="prediction-card"\u003e
            \u003ch3 class="pred-title"\u003eD·ª± b√°o T+7\u003c/h3\u003e
            \u003ch1 class="pred-price"\u003e${pred['price']:.4f}\u003c/h1\u003e
            \u003cp class="pred-sub"\u003e{pred['date'].strftime('%d/%m/%Y')}\u003c/p\u003e
        \u003c/div\u003e
        """, unsafe_allow_html=True)


def display_ml_ensemble_results():
    """Display ML Ensemble training \u0026 prediction results"""
    st.subheader("K·∫øt qu·∫£ ML Ensemble")
    
    metrics = st.session_state.ml_ensemble_metrics
    test_metrics = metrics['test']
    
    # Metrics
    col1, col2, col3 = st.columns(3)
    col1.metric("MAE (Test)", f"{test_metrics['mae']:.4f}")
    col2.metric("RMSE (Test)", f"{test_metrics['rmse']:.4f}")
    
    # Individual model R¬≤ scores
    if 'train' in metrics:
        st.write("**Individual Model Scores:**")
        train_metrics = metrics['train']
        
        cols = st.columns(3)
        for i, (name, m) in enumerate(train_metrics.items()):
            cols[i].metric(f"{name} R¬≤", f"{m['train_r2']:.4f}")
    
    # Prediction display
    if 'ml_ensemble_prediction' in st.session_state:
        pred = st.session_state.ml_ensemble_prediction
        
        st.markdown(f"""
        \u003cdiv class="prediction-card"\u003e
            \u003ch3 class="pred-title"\u003eD·ª± b√°o T+7\u003c/h3\u003e
            \u003ch1 class="pred-price"\u003e${pred['price']:.4f}\u003c/h1\u003e
            \u003cp class="pred-sub"\u003e{pred['date'].strftime('%d/%m/%Y')}\u003c/p\u003e
        \u003c/div\u003e
        """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
